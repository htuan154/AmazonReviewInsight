<!DOCTYPE html>
<html lang="vi">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Day 3 V2 - Auto-Tuning Training Report (November 1, 2025)</title>
  <style>
    body{font-family:'Segoe UI',Tahoma,Arial,sans-serif;background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:#222;margin:0;padding:24px}
    .container{max-width:1400px;margin:0 auto}
    .hero{background:linear-gradient(135deg,#1e3c72 0%,#2a5298 100%);color:#fff;border-radius:16px;padding:40px;margin-bottom:24px;box-shadow:0 20px 60px rgba(0,0,0,0.3)}
    .hero h1{margin:0 0 12px;font-size:2.5em;font-weight:700}
    .hero .subtitle{font-size:1.1em;opacity:0.9;margin:0}
    .grid{display:grid;grid-template-columns:repeat(auto-fit,minmax(350px,1fr));gap:20px;margin-bottom:20px}
    .card{background:#fff;border-radius:12px;padding:24px;box-shadow:0 8px 30px rgba(0,0,0,0.12);transition:transform 0.2s}
    .card:hover{transform:translateY(-4px);box-shadow:0 12px 40px rgba(0,0,0,0.15)}
    .card-full{grid-column:1/-1}
    h2{color:#1f4ed8;margin:0 0 16px;font-size:1.5em;border-bottom:3px solid #1f4ed8;padding-bottom:8px}
    h3{color:#333;margin:20px 0 12px;font-size:1.2em}
    .metric-grid{display:grid;grid-template-columns:repeat(auto-fit,minmax(200px,1fr));gap:16px;margin:16px 0}
    .metric-box{background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:#fff;padding:20px;border-radius:10px;text-align:center}
    .metric-box .label{font-size:0.9em;opacity:0.9;margin-bottom:8px}
    .metric-box .value{font-size:2em;font-weight:700}
    .code-block{background:#0d1117;color:#c9d1d9;padding:16px;border-radius:8px;overflow-x:auto;margin:12px 0;border-left:4px solid #58a6ff}
    .code-block pre{margin:0;font-family:'Consolas','Monaco','Courier New',monospace;font-size:0.9em}
    table{width:100%;border-collapse:collapse;margin:16px 0}
    th,td{padding:12px;text-align:left;border-bottom:1px solid #e5e7eb}
    th{background:#f3f4f6;color:#1f4ed8;font-weight:600}
    tr:hover{background:#f9fafb}
    .badge{display:inline-block;padding:6px 12px;border-radius:20px;font-size:0.85em;font-weight:600;margin:4px}
    .badge-success{background:#d1fae5;color:#065f46}
    .badge-info{background:#dbeafe;color:#1e40af}
    .badge-warning{background:#fef3c7;color:#92400e}
    .muted{color:#6b7280;font-size:0.95em}
    .feature-list{background:#f9fafb;padding:16px;border-radius:8px;border-left:4px solid #10b981}
    .section{margin-bottom:24px}
    .note{background:#fff3cd;border-left:4px solid #ffc107;padding:12px 16px;border-radius:4px;margin:12px 0}
    .success-box{background:#d1fae5;border-left:4px solid #10b981;padding:12px 16px;border-radius:4px;margin:12px 0}
    img{max-width:100%;border-radius:8px;box-shadow:0 4px 12px rgba(0,0,0,0.1);margin:12px 0}
    .workflow{background:#f3f4f6;padding:20px;border-radius:8px;margin:16px 0}
    .workflow-step{background:#fff;padding:16px;margin:12px 0;border-radius:8px;border-left:4px solid #667eea;box-shadow:0 2px 8px rgba(0,0,0,0.05)}
    .workflow-step h4{margin:0 0 8px;color:#667eea}
  </style>
</head>
<body>
  <div class="container">
    <div class="hero">
      <h1>ÔøΩ Day 3 V2 ‚Äî Auto-Tuning LightGBM Training</h1>
      <p class="subtitle">Hyperparameter Tuning v·ªõi 3-Fold Cross-Validation & Semi-Supervised Learning</p>
      <div style="margin-top:16px">
        <span class="badge badge-info">Author: V√µ Th·ªã Di·ªÖm Thanh</span>
        <span class="badge badge-info">Date: November 1, 2025</span>
        <span class="badge badge-success">Status: Auto-Tuning Completed ‚úì</span>
      </div>
    </div>

    <!-- Executive Summary -->
    <div class="card card-full">
      <h2>üìä Executive Summary</h2>
      <div class="success-box">
        <strong>üéØ Auto-Tuning Results:</strong> Sau khi th·ª≠ 9 combinations v·ªõi 3-fold CV (27 training runs), t√¨m ƒë∆∞·ª£c hyperparameters t·ªëi ∆∞u: <strong>numLeaves=100, learningRate=0.15</strong>. Model cu·ªëi ƒë·∫°t <strong>AUC-PR = 0.6315</strong> tr√™n validation set v·ªõi 5M training samples.
      </div>
      
      <div class="metric-grid">
        <div class="metric-box">
          <div class="label">Best CV AUC-PR</div>
          <div class="value">0.642</div>
        </div>
        <div class="metric-box">
          <div class="label">Final Val AUC-PR</div>
          <div class="value">0.632</div>
        </div>
        <div class="metric-box">
          <div class="label">CV Configurations</div>
          <div class="value">9</div>
        </div>
        <div class="metric-box">
          <div class="label">Total Training Runs</div>
          <div class="value">27</div>
        </div>
      </div>

      <div class="note">
        <strong>‚öôÔ∏è Training Strategy:</strong> S·ª≠ d·ª•ng <strong>limit_train=5M</strong> samples (thay v√¨ full 15.6M) ƒë·ªÉ t·ªëi ∆∞u th·ªùi gian training trong deadline 12 gi·ªù. Grid search v·ªõi quick preset (3√ó3 grid) cho numLeaves v√† learningRate.
      </div>
    </div>

    <!-- Training Command & Explanation -->
    <div class="card card-full">
      <h2>üöÄ Auto-Tuning Command Used</h2>
      <p>L·ªánh th·ª±c t·∫ø ƒë√£ ch·∫°y ƒë·ªÉ auto-tune hyperparameters:</p>
      
      <div class="code-block">
        <pre>spark-submit \
  --master local[*] \
  --deploy-mode client \
  --packages com.microsoft.azure:synapseml-lightgbm_2.12:1.0.7 \
  --driver-memory 11g \
  --executor-memory 11g \
  --conf spark.driver.maxResultSize=4g \
  --conf spark.sql.shuffle.partitions=64 \
  --conf spark.sql.adaptive.enabled=true \
  "train_lightgbm_spark_v2.py" \
  --train "hdfs://localhost:9000/output_v2/features_train_v4" \
  --test "hdfs://localhost:9000/output_v2/features_test_v4" \
  --out "hdfs://localhost:9000/output_v2/models/lightgbm_v7_auto" \
  --limit_train 5000000 \
  --auto_tune \
  --tune_preset quick \
  --save_schema_log</pre>
      </div>

      <h3>üìù Gi·∫£i th√≠ch c√°c tham s·ªë:</h3>
      <table>
        <thead>
          <tr><th>Parameter</th><th>Value</th><th>Explanation</th></tr>
        </thead>
        <tbody>
          <tr>
            <td><code>--master local[*]</code></td>
            <td>local[*]</td>
            <td>Ch·∫°y Spark local mode, s·ª≠ d·ª•ng t·∫•t c·∫£ CPU cores (16 cores)</td>
          </tr>
          <tr>
            <td><code>--driver-memory</code></td>
            <td>11g</td>
            <td>C·∫•p ph√°t 11GB RAM cho Spark driver (t·ªïng 22GB v·ªõi executor)</td>
          </tr>
          <tr>
            <td><code>--executor-memory</code></td>
            <td>11g</td>
            <td>C·∫•p ph√°t 11GB RAM cho Spark executor (~70% RAM h·ªá th·ªëng)</td>
          </tr>
          <tr>
            <td><code>--limit_train</code></td>
            <td>5,000,000</td>
            <td>Gi·ªõi h·∫°n 5M samples (thay v√¨ full 15.6M) ƒë·ªÉ t·ªëi ∆∞u th·ªùi gian</td>
          </tr>
          <tr>
            <td><code>--auto_tune</code></td>
            <td>enabled</td>
            <td><strong>B·∫≠t auto-tuning</strong>: t·ª± ƒë·ªông t√¨m hyperparameters t·ªëi ∆∞u</td>
          </tr>
          <tr>
            <td><code>--tune_preset</code></td>
            <td>quick</td>
            <td>Quick preset: 9 combinations (3√ó3 grid), ~2-3 gi·ªù</td>
          </tr>
          <tr>
            <td><code>Grid Search</code></td>
            <td>9 combos</td>
            <td>numLeaves=[31,50,100] √ó learningRate=[0.05,0.1,0.15]</td>
          </tr>
          <tr>
            <td><code>Cross-Validation</code></td>
            <td>3-fold</td>
            <td>Stratified 3-fold CV ‚Üí 9 √ó 3 = <strong>27 training runs</strong></td>
          </tr>
          <tr>
            <td><code>Evaluation Metric</code></td>
            <td>AUC-PR</td>
            <td>Average Precision (ph√π h·ª£p v·ªõi imbalanced data)</td>
          </tr>
          <tr>
            <td><code>Class Weight</code></td>
            <td>3.054</td>
            <td>Auto-computed: neg/pos = 3,389,339/1,109,945 = 3.054</td>
          </tr>
          <tr>
            <td><code>Feature Dimension</code></td>
            <td>10,017</td>
            <td>10K TF-IDF features + 17 numeric/boolean features</td>
          </tr>
        </tbody>
      </table>
    </div>

    <!-- Algorithms & Techniques -->
    <div class="card card-full">
      <h2>üß† Thu·∫≠t To√°n & K·ªπ Thu·∫≠t S·ª≠ D·ª•ng</h2>
      
      <h3>1Ô∏è‚É£ LightGBM (Light Gradient Boosting Machine)</h3>
      <div class="feature-list">
        <p><strong>Kh√°i ni·ªám:</strong> Gradient Boosting Decision Trees (GBDT) t·ªëi ∆∞u, s·ª≠ d·ª•ng histogram-based learning v√† leaf-wise growth.</p>
        
        <p><strong>∆Øu ƒëi·ªÉm:</strong></p>
        <ul>
          <li>‚ö° <strong>T·ªëc ƒë·ªô cao:</strong> Histogram-based algorithm ‚Üí gi·∫£m memory & tƒÉng t·ªëc training</li>
          <li>üìä <strong>X·ª≠ l√Ω high-dimensional data:</strong> 10K features v·∫´n train nhanh</li>
          <li>üéØ <strong>Leaf-wise growth:</strong> TƒÉng accuracy so v·ªõi level-wise (XGBoost)</li>
          <li>üîß <strong>Regularization:</strong> L1/L2, min_data_in_leaf, feature_fraction ‚Üí ch·ªëng overfitting</li>
        </ul>
        
        <p><strong>C√°ch ho·∫°t ƒë·ªông:</strong></p>
        <ul>
          <li>Build c√¢y quy·∫øt ƒë·ªãnh tu·∫ßn t·ª±, m·ªói c√¢y h·ªçc t·ª´ residual (sai s·ªë) c·ªßa c√¢y tr∆∞·ªõc</li>
          <li>Loss function: Binary Cross-Entropy (log loss) cho binary classification</li>
          <li>Optimization: Gradient descent tr√™n loss function</li>
          <li>Prediction: T·ªïng weighted output c·ªßa t·∫•t c·∫£ c√¢y ‚Üí sigmoid ‚Üí probability [0,1]</li>
        </ul>
      </div>

      <h3>2Ô∏è‚É£ Hyperparameter Tuning (Grid Search with Cross-Validation)</h3>
      <div class="feature-list">
        <p><strong>Kh√°i ni·ªám:</strong> T√¨m ki·∫øm exhaustive tr√™n grid space ƒë·ªÉ t√¨m combination t·ªëi ∆∞u.</p>
        
        <p><strong>Grid Space (Quick Preset):</strong></p>
        <ul>
          <li><code>numLeaves</code>: [31, 50, 100] ‚Üí Tree complexity (s·ªë l√°/c√¢y)</li>
          <li><code>learningRate</code>: [0.05, 0.1, 0.15] ‚Üí Step size trong gradient descent</li>
          <li>Total combinations: 3 √ó 3 = <strong>9 configs</strong></li>
        </ul>
        
        <p><strong>3-Fold Stratified Cross-Validation:</strong></p>
        <ul>
          <li>Split data th√†nh 3 folds, gi·ªØ nguy√™n class distribution (stratified)</li>
          <li>M·ªói fold l√†m validation 1 l·∫ßn, 2 folds c√≤n l·∫°i l√†m training</li>
          <li>Mean AUC-PR c·ªßa 3 folds = metric ƒë√°nh gi√° combo</li>
          <li>Total runs: 9 combos √ó 3 folds = <strong>27 training runs</strong></li>
        </ul>
        
        <p><strong>Best Params Selection:</strong></p>
        <ul>
          <li>Ch·ªçn combo c√≥ <strong>Mean CV AUC-PR cao nh·∫•t</strong></li>
          <li>K·∫øt qu·∫£: <code>numLeaves=100, learningRate=0.15</code> ‚Üí AUC-PR = 0.6417</li>
          <li>Retrain model cu·ªëi tr√™n full training data v·ªõi best params</li>
        </ul>
      </div>

      <h3>3Ô∏è‚É£ Semi-Supervised Learning (Pseudo-Labeling) - Optional</h3>
      <div class="feature-list">
        <p><strong>Kh√°i ni·ªám:</strong> S·ª≠ d·ª•ng unlabeled data (test set) ƒë·ªÉ tƒÉng training data.</p>
        
        <p><strong>Workflow:</strong></p>
        <ul>
          <li>Train model base tr√™n labeled data (5M samples)</li>
          <li>Predict tr√™n test set ‚Üí l·∫•y high-confidence predictions l√†m pseudo-labels</li>
          <li>Th√™m pseudo-labeled data v√†o training set ‚Üí retrain model</li>
          <li>Iterate cho ƒë·∫øn khi converge ho·∫∑c h·∫øt iteration</li>
        </ul>
        
        <p><strong>L∆∞u √Ω:</strong> Code c√≥ support nh∆∞ng <strong>kh√¥ng enable</strong> trong run n√†y (ch·ªâ supervised learning).</p>
      </div>

      <h3>4Ô∏è‚É£ Class Imbalance Handling</h3>
      <div class="feature-list">
        <p><strong>V·∫•n ƒë·ªÅ:</strong> Class imbalance 1:3 (helpful=1: 1.1M vs unhelpful=0: 3.4M)</p>
        
        <p><strong>Gi·∫£i ph√°p:</strong></p>
        <ul>
          <li><strong>Scale Pos Weight:</strong> TƒÉng weight cho class thi·ªÉu s·ªë (helpful=1)</li>
          <li>C√¥ng th·ª©c: <code>weight = neg_count / pos_count = 3,389,339 / 1,109,945 = 3.054</code></li>
          <li>Effect: Loss c·ªßa positive samples ƒë∆∞·ª£c nh√¢n v·ªõi 3.054 ‚Üí model focus h∆°n v√†o class n√†y</li>
          <li><strong>Stratified Sampling:</strong> CV split gi·ªØ nguy√™n t·ª∑ l·ªá class trong m·ªói fold</li>
          <li><strong>Metric:</strong> AUC-PR (kh√¥ng ph·∫£i accuracy) ‚Üí ph√π h·ª£p v·ªõi imbalanced data</li>
        </ul>
      </div>

      <h3>5Ô∏è‚É£ Feature Engineering (Day 2)</h3>
      <div class="feature-list">
        <p><strong>TF-IDF Vectorization (10,000 features):</strong></p>
        <ul>
          <li>Tokenize review text ‚Üí compute Term Frequency - Inverse Document Frequency</li>
          <li>Max features: 10,000 (top frequent terms)</li>
          <li>Captures semantic information t·ª´ review content</li>
        </ul>
        
        <p><strong>Metadata Features (17 numeric/boolean):</strong></p>
        <ul>
          <li>User behavior: user_review_count, user_helpful_ratio, user_avg_rating</li>
          <li>Product aggregates: product_review_count, product_helpful_ratio, product_avg_rating</li>
          <li>Review quality: review_length, review_length_log, rating_deviation</li>
          <li>Category indicators: is_popular_category, has_metadata, is_expensive</li>
        </ul>
      </div>

      <h3>6Ô∏è‚É£ KMeans Clustering (Optional - Synthetic Labels)</h3>
      <div class="feature-list">
        <p><strong>Kh√°i ni·ªám:</strong> Unsupervised learning algorithm ƒë·ªÉ ph√¢n nh√≥m data th√†nh K clusters.</p>
        
        <p><strong>Workflow trong code:</strong></p>
        <div class="code-block">
          <pre>from pyspark.ml.clustering import KMeans

# Initialize KMeans v·ªõi k=2 (binary classification)
kmeans = KMeans(
    featuresCol='features',  # Vector column (10,017 dims)
    k=2,                     # 2 clusters (helpful vs not helpful)
    seed=42,                 # Reproducible
    maxIter=20               # Max iterations
)

# Train clustering model
model = kmeans.fit(df)

# Predict cluster assignments (0 ho·∫∑c 1)
df = model.transform(df)  # Adds 'prediction' column

# Use cluster ID as synthetic label
df = df.withColumn('is_helpful', col('prediction').cast(IntegerType()))</pre>
        </div>
        
        <p><strong>Chi ti·∫øt algorithm:</strong></p>
        <ul>
          <li><strong>Initialization:</strong> Random ch·ªçn 2 centroids (cluster centers) trong feature space</li>
          <li><strong>Assignment step:</strong> Assign m·ªói data point v√†o cluster g·∫ßn nh·∫•t (Euclidean distance)</li>
          <li><strong>Update step:</strong> T√≠nh l·∫°i centroid c·ªßa m·ªói cluster (mean c·ªßa t·∫•t c·∫£ points trong cluster)</li>
          <li><strong>Iterate:</strong> L·∫∑p assignment + update cho ƒë·∫øn khi converge (centroids kh√¥ng ƒë·ªïi) ho·∫∑c maxIter</li>
        </ul>
        
        <p><strong>∆Øu ƒëi·ªÉm:</strong></p>
        <ul>
          <li>‚úì Kh√¥ng c·∫ßn labeled data (unsupervised)</li>
          <li>‚úì T·ª± ƒë·ªông t√¨m patterns trong high-dimensional space (10K features)</li>
          <li>‚úì Fast & scalable v·ªõi PySpark distributed computing</li>
        </ul>
        
        <p><strong>Nh∆∞·ª£c ƒëi·ªÉm:</strong></p>
        <ul>
          <li>‚úó Cluster assignment kh√¥ng guarantee t∆∞∆°ng ·ª©ng v·ªõi helpful/unhelpful th·ª±c t·∫ø</li>
          <li>‚úó Sensitive to initialization (random seed)</li>
          <li>‚úó Assumes spherical clusters (Euclidean distance)</li>
        </ul>
        
        <p><strong>Khi n√†o d√πng KMeans?</strong></p>
        <ul>
          <li>Test set kh√¥ng c√≥ labels ‚Üí d√πng KMeans ƒë·ªÉ t·∫°o synthetic labels</li>
          <li>Exploratory analysis ‚Üí t√¨m natural groupings trong data</li>
          <li>Heuristic method kh√¥ng ho·∫°t ƒë·ªông t·ªët (thi·∫øu features nh∆∞ rating, sentiment)</li>
        </ul>
        
        <div class="note">
          <strong>üìù L∆∞u √Ω:</strong> Trong auto-tune run n√†y, <strong>kh√¥ng s·ª≠ d·ª•ng KMeans</strong> v√¨ training data ƒë√£ c√≥ ground truth labels (is_helpful). KMeans ch·ªâ d√πng khi c·∫ßn generate synthetic labels cho unlabeled data.
        </div>
      </div>
    </div>

    <!-- Code Functions Detailed Explanation -->
    <div class="card card-full">
      <h2>üîç Chi Ti·∫øt Code - C√°c H√†m Ch√≠nh</h2>
      <p>Gi·∫£i th√≠ch chi ti·∫øt t·ª´ng h√†m quan tr·ªçng trong <code>train_lightgbm_spark_v2.py</code>:</p>

      <h3>1. <code>generate_synthetic_labels()</code> - T·∫°o Labels T·ª± ƒê·ªông</h3>
      <div class="code-block">
        <pre>def generate_synthetic_labels(df, label_col, method='heuristic', seed=42):
    """
    T·∫°o synthetic labels khi kh√¥ng c√≥ ground truth.
    
    Methods:
    - 'heuristic': D√πng rating + review length + sentiment (rule-based)
    - 'clustering': D√πng KMeans ƒë·ªÉ t√¨m nh√≥m t·ª± nhi√™n (unsupervised)
    """</pre>
      </div>
      <p><strong>M·ª•c ƒë√≠ch:</strong> Khi test set kh√¥ng c√≥ label (is_helpful), t·∫°o pseudo-labels ƒë·ªÉ train.</p>
      
      <h4>Method 1: Heuristic (Rule-based)</h4>
      <div class="feature-list">
        <p><strong>Logic:</strong> T√≠nh ƒëi·ªÉm d·ª±a tr√™n nhi·ªÅu y·∫øu t·ªë:</p>
        <ul>
          <li><strong>star_rating:</strong> Rating cao (4-5 sao) ‚Üí helpful h∆°n. Normalize v·ªÅ [0,1]</li>
          <li><strong>review_length_log:</strong> Reviews d√†i ‚Üí informative h∆°n. Normalize v·ªÅ [0,1]</li>
          <li><strong>sentiment_compound:</strong> Sentiment positive ‚Üí helpful h∆°n</li>
          <li><strong>user_helpful_ratio:</strong> User c√≥ l·ªãch s·ª≠ helpful ‚Üí reviews helpful h∆°n</li>
        </ul>
        <p><strong>C√¥ng th·ª©c:</strong></p>
        <div class="code-block">
          <pre># Weighted score
score = (star_rating * 0.3 + 
         review_length_log * 0.25 + 
         sentiment * 0.2 + 
         user_helpful_ratio * 0.25)

# Threshold = median
if score >= median(score):
    label = 1  # helpful
else:
    label = 0  # not helpful</pre>
        </div>
      </div>

      <h4>Method 2: KMeans Clustering</h4>
      <div class="feature-list">
        <p><strong>Logic:</strong> D√πng unsupervised learning ƒë·ªÉ ph√¢n nh√≥m t·ª± nhi√™n:</p>
        <div class="code-block">
          <pre>from pyspark.ml.clustering import KMeans

# Train KMeans v·ªõi k=2 clusters
kmeans = KMeans(featuresCol='features', k=2, seed=42, maxIter=20)
model = kmeans.fit(df)

# Predict cluster assignments
df = model.transform(df)  # Column 'prediction' = 0 ho·∫∑c 1

# S·ª≠ d·ª•ng cluster ID l√†m label
df = df.withColumn(label_col, col('prediction').cast(IntegerType()))</pre>
        </div>
        <p><strong>∆Øu ƒëi·ªÉm:</strong> Kh√¥ng c·∫ßn feature engineering, t√¨m patterns t·ª± nhi√™n trong data.</p>
        <p><strong>Nh∆∞·ª£c ƒëi·ªÉm:</strong> Cluster kh√¥ng ƒë·∫£m b·∫£o t∆∞∆°ng ·ª©ng v·ªõi helpful/unhelpful th·ª±c t·∫ø.</p>
      </div>

      <h3>2. <code>stratified_kfold_split()</code> - Chia K-Fold Stratified</h3>
      <div class="code-block">
        <pre>def stratified_kfold_split(df, label_col, n_folds=3, seed=42):
    """
    Stratified K-Fold: chia data th√†nh K folds, gi·ªØ class balance.
    Returns: list of (train_fold, val_fold) tuples
    """
    # Assign fold ID proportionally within each class
    window = Window.partitionBy(label_col).orderBy(rand(seed))
    df = df.withColumn("__row_num__", row_number().over(window))
    df = df.withColumn("__fold__", (col("__row_num__") % n_folds).cast("int"))
    
    # Create folds
    for fold_idx in range(n_folds):
        val_fold = df.filter(col("__fold__") == fold_idx)
        train_fold = df.filter(col("__fold__") != fold_idx)
        yield (train_fold, val_fold)</pre>
      </div>
      <p><strong>Gi·∫£i th√≠ch:</strong></p>
      <ul>
        <li><strong>Window.partitionBy(label_col):</strong> Chia data theo class (0 v√† 1 ri√™ng bi·ªát)</li>
        <li><strong>row_number():</strong> ƒê√°nh s·ªë th·ª© t·ª± trong m·ªói class</li>
        <li><strong>% n_folds:</strong> Chia ƒë·ªÅu: row 0,3,6,... ‚Üí fold 0; row 1,4,7,... ‚Üí fold 1; etc.</li>
        <li><strong>K·∫øt qu·∫£:</strong> M·ªói fold c√≥ t·ª∑ l·ªá class gi·ªëng nhau (1:3 ratio maintained)</li>
      </ul>

      <h3>3. <code>hyperparameter_tuning()</code> - Grid Search + CV</h3>
      <div class="code-block">
        <pre>def hyperparameter_tuning(train_df, label_col, features_col, args, preset="quick"):
    """
    Grid search v·ªõi 3-fold CV ƒë·ªÉ t√¨m best hyperparameters.
    
    Quick preset: 9 combos (3√ó3 grid)
    Thorough preset: 27 combos (3√ó3√ó3 grid)
    """
    # Define grid
    param_grid = {
        "numLeaves": [31, 50, 100],
        "learningRate": [0.05, 0.1, 0.15]
    }
    
    # Generate all combinations
    all_combos = list(product(*param_grid.values()))  # 9 combos
    
    # Create 3-fold stratified split
    folds = stratified_kfold_split(train_df, label_col, n_folds=3)
    
    # Grid search
    for combo in all_combos:
        params = dict(zip(param_grid.keys(), combo))
        
        # Cross-validation
        fold_scores = []
        for train_fold, val_fold in folds:
            # Train model v·ªõi params n√†y
            model = LightGBMClassifier(**params).fit(train_fold)
            
            # Evaluate tr√™n val_fold
            auc_pr = evaluate(model, val_fold)
            fold_scores.append(auc_pr)
        
        # Compute mean & std
        mean_aucpr = mean(fold_scores)
        std_aucpr = stdev(fold_scores)
    
    # Return best params
    best_params = max(results, key=lambda x: x['mean_aucpr'])</pre>
      </div>
      <p><strong>Chi ti·∫øt workflow:</strong></p>
      <ul>
        <li><strong>itertools.product():</strong> Generate Cartesian product (all combinations)</li>
        <li><strong>3-Fold CV:</strong> Train 3 l·∫ßn m·ªói combo ‚Üí 9 √ó 3 = 27 training runs</li>
        <li><strong>mean(fold_scores):</strong> Average AUC-PR c·ªßa 3 folds = metric ƒë√°nh gi√° combo</li>
        <li><strong>std(fold_scores):</strong> Standard deviation ‚Üí ƒëo stability (low variance = better)</li>
        <li><strong>Best selection:</strong> Ch·ªçn combo c√≥ mean AUC-PR cao nh·∫•t</li>
      </ul>

      <h3>4. <code>compute_class_weight()</code> - X·ª≠ L√Ω Imbalance</h3>
      <div class="code-block">
        <pre>def compute_class_weight(df, label_col, weight_col="weight", pos_weight=None):
    """
    T√≠nh class weight ƒë·ªÉ handle imbalanced data.
    pos_weight: 'auto' ‚Üí N_neg/N_pos, ho·∫∑c float value
    """
    # Count positive and negative samples
    pos = df.filter(col(label_col) == 1).count()  # helpful
    neg = df.filter(col(label_col) == 0).count()  # not helpful
    
    if pos_weight == "auto":
        # Auto-compute weight ratio
        w1 = max(0.1, min(10.0, float(neg) / float(pos)))
        # Clamp to [0.1, 10] ƒë·ªÉ tr√°nh extreme values
    
    # Assign weight column
    df = df.withColumn(weight_col, 
                       when(col(label_col) == 1, lit(w1)).otherwise(lit(1.0)))
    
    return df, w1, pos, neg</pre>
      </div>
      <p><strong>Gi·∫£i th√≠ch c√¥ng th·ª©c:</strong></p>
      <ul>
        <li><strong>weight = neg/pos:</strong> V√≠ d·ª• 3,389,339 / 1,109,945 = 3.054</li>
        <li><strong>Effect:</strong> Loss c·ªßa positive samples nh√¢n v·ªõi 3.054 ‚Üí model focus h∆°n</li>
        <li><strong>Clamp [0.1, 10]:</strong> Tr√°nh extreme weights (too high ‚Üí overfitting minority class)</li>
        <li><strong>LightGBM classWeight:</strong> Format "0:1,1:3.054" ‚Üí class 0 weight=1, class 1 weight=3.054</li>
      </ul>

      <h3>5. <code>evaluate_model()</code> - Comprehensive Metrics</h3>
      <div class="code-block">
        <pre>def evaluate_model(model, df, label_col, stage_name="VAL"):
    """
    Evaluate model v·ªõi nhi·ªÅu metrics.
    Returns: (metrics, pred_df)
    """
    # Binary classification metrics
    eval_pr = BinaryClassificationEvaluator(metricName="areaUnderPR")
    eval_roc = BinaryClassificationEvaluator(metricName="areaUnderROC")
    
    pred_df = model.transform(df)
    aucpr = eval_pr.evaluate(pred_df)
    aucroc = eval_roc.evaluate(pred_df)
    
    # Multiclass metrics (for Precision, Recall, F1)
    evaluator_precision = MulticlassClassificationEvaluator(
        metricName="weightedPrecision")
    evaluator_recall = MulticlassClassificationEvaluator(
        metricName="weightedRecall")
    evaluator_f1 = MulticlassClassificationEvaluator(
        metricName="f1")
    
    precision = evaluator_precision.evaluate(pred_df)
    recall = evaluator_recall.evaluate(pred_df)
    f1 = evaluator_f1.evaluate(pred_df)
    
    # Confusion matrix
    cm_df = pred_df.groupBy(label_col, "prediction").count().collect()
    tp = confusion_matrix.get("true_1_pred_1", 0)
    tn = confusion_matrix.get("true_0_pred_0", 0)
    fp = confusion_matrix.get("true_0_pred_1", 0)
    fn = confusion_matrix.get("true_1_pred_0", 0)
    
    return metrics, pred_df</pre>
      </div>
      <p><strong>Metrics explained:</strong></p>
      <table>
        <thead>
          <tr><th>Metric</th><th>Formula</th><th>Meaning</th></tr>
        </thead>
        <tbody>
          <tr><td><strong>AUC-PR</strong></td><td>Area Under Precision-Recall Curve</td><td>T·ªët cho imbalanced data (focus on positive class)</td></tr>
          <tr><td><strong>AUC-ROC</strong></td><td>Area Under ROC Curve</td><td>Overall classification performance (TPR vs FPR)</td></tr>
          <tr><td><strong>Precision</strong></td><td>TP / (TP + FP)</td><td>% predictions ch√≠nh x√°c trong nh·ªØng g√¨ model d·ª± ƒëo√°n l√† helpful</td></tr>
          <tr><td><strong>Recall</strong></td><td>TP / (TP + FN)</td><td>% helpful reviews m√† model t√¨m ƒë∆∞·ª£c (sensitivity)</td></tr>
          <tr><td><strong>F1-Score</strong></td><td>2 √ó (Precision √ó Recall) / (Precision + Recall)</td><td>Harmonic mean c·ªßa Precision & Recall (balanced metric)</td></tr>
        </tbody>
      </table>

      <h3>6. <code>pseudo_label_iteration()</code> - Semi-Supervised Learning</h3>
      <div class="code-block">
        <pre>def pseudo_label_iteration(model, unlabeled_df, label_col, 
                                 min_prob=0.9, top_pct=0.1, pseudo_weight=0.3):
    """
    Pseudo-labeling: d√πng high-confidence predictions l√†m labels.
    """
    # Predict tr√™n unlabeled data
    pred_df = model.transform(unlabeled_df)
    
    # Extract probability for class 1
    get_prob_udf = udf(lambda v: float(v[1]) if v else 0.0, FloatType())
    pred_df = pred_df.withColumn("prob_class1", get_prob_udf(col("probability")))
    
    # Select confident samples
    confident_pos = pred_df.filter(col("prob_class1") >= 0.9)  # prob ‚â• 90%
    confident_neg = pred_df.filter(col("prob_class1") <= 0.1)  # prob ‚â§ 10%
    
    # Take top 10% by confidence
    n_pos = int(confident_pos.count() * 0.1)
    n_neg = int(confident_neg.count() * 0.1)
    
    pseudo_pos = confident_pos.orderBy(desc("prob_class1")).limit(n_pos) \
        .withColumn(label_col, lit(1))
    pseudo_neg = confident_neg.orderBy(asc("prob_class1")).limit(n_neg) \
        .withColumn(label_col, lit(0))
    
    # Assign low weight (0.3) cho pseudo-labels
    pseudo_df = pseudo_pos.union(pseudo_neg)
    pseudo_df = pseudo_df.withColumn("weight", lit(0.3))
    
    return pseudo_df</pre>
      </div>
      <p><strong>Workflow:</strong></p>
      <ol>
        <li><strong>Predict:</strong> Model d·ª± ƒëo√°n tr√™n unlabeled data (test set)</li>
        <li><strong>Filter confident:</strong> Ch·ªâ l·∫•y samples v·ªõi prob ‚â• 90% (positive) ho·∫∑c ‚â§ 10% (negative)</li>
        <li><strong>Top selection:</strong> Ch·ªçn top 10% confident nh·∫•t ‚Üí pseudo-labels</li>
        <li><strong>Low weight:</strong> Assign weight=0.3 (th·∫•p h∆°n real labels) v√¨ kh√¥ng ch·∫Øc ch·∫Øn 100%</li>
        <li><strong>Retrain:</strong> Th√™m pseudo-labeled data v√†o training set ‚Üí retrain model</li>
      </ol>
      <p><strong>L∆∞u √Ω:</strong> Trong run n√†y <strong>kh√¥ng enable</strong> pseudo-labeling (pseudo_rounds=0).</p>
    </div>

    <!-- Code Workflow -->
    <div class="card card-full">
      <h2>üîß Code Workflow (train_lightgbm_spark_v2.py)</h2>
      <p>File th·ª±c hi·ªán workflow auto-tuning v·ªõi PySpark + SynapseML:</p>

      <div class="workflow">
        <div class="workflow-step">
          <h4>Step 1: Load Data from HDFS v·ªõi PySpark</h4>
          <div class="code-block">
            <pre># Load Parquet t·ª´ HDFS qua Spark
train_df = spark.read.parquet("hdfs://localhost:9000/output_v2/features_train_v4")
test_df = spark.read.parquet("hdfs://localhost:9000/output_v2/features_test_v4")

# Limit training samples (t·ªëi ∆∞u th·ªùi gian)
if limit_train:
    train_df = train_df.limit(5000000)  # 5M samples

# Feature dimension: 10,017 (TF-IDF 10K + numeric 17)</pre>
          </div>
          <p class="muted">‚úì Spark distributed loading ‚Üí handle large files (GB scale)</p>
          <p class="muted">‚úì HDFS URI: hdfs://localhost:9000/... (JNI connector)</p>
        </div>

        <div class="workflow-step">
          <h4>Step 2: Stratified Train/Val Split</h4>
          <div class="code-block">
            <pre># Custom stratified split (PySpark kh√¥ng c√≥ built-in)
def stratified_kfold_split(df, label_col, n_splits=3, seed=42):
    # Split theo label distribution
    pos = df.filter(f"{label_col} = 1")
    neg = df.filter(f"{label_col} = 0")
    
    # Random split m·ªói class
    for fold in range(n_splits):
        train_folds = [...]  # Other folds
        val_fold = fold
        yield train_folds, val_fold

# T·∫°o 90% train, 10% val (gi·ªØ class balance)
train_df, val_df = stratified_split(train_df, "is_helpful")</pre>
          </div>
          <p class="muted">‚úì Stratified: gi·ªØ ratio 1:3 (helpful:unhelpful) trong m·ªói fold</p>
          <p class="muted">‚úì Seed=42: reproducible splits</p>
        </div>

        <div class="workflow-step">
          <h4>Step 3: Compute Class Weight</h4>
          <div class="code-block">
            <pre># ƒê·∫øm class balance
neg_count = train_df.filter("is_helpful = 0").count()  # 3,389,339
pos_count = train_df.filter("is_helpful = 1").count()  # 1,109,945

# Scale pos weight (cho LightGBM)
pos_weight = neg_count / pos_count  # 3.054
lgbm_params["classWeight"] = f"0:{1},1:{pos_weight}"</pre>
          </div>
          <p class="muted">‚úì Auto-computed: kh√¥ng c·∫ßn manual tuning</p>
          <p class="muted">‚úì Format: "0:1,1:3.054" ‚Üí LightGBM weighted loss</p>
        </div>

        <div class="workflow-step">
          <h4>Step 4: Grid Search v·ªõi 3-Fold CV</h4>
          <div class="code-block">
            <pre># Define grid space (quick preset)
param_grid = {
    "numLeaves": [31, 50, 100],
    "learningRate": [0.05, 0.1, 0.15]
}

# Generate all combinations
combos = list(itertools.product(*param_grid.values()))  # 9 combos

# 3-Fold Cross-Validation
results = []
for combo in combos:
    for train_fold, val_fold in kfold_split(train_df, n_splits=3):
        # Train LightGBM v·ªõi combo n√†y
        model = LightGBMClassifier(**combo_params)
        model.fit(train_fold)
        
        # Evaluate tr√™n val_fold
        auc_pr = evaluate(model, val_fold)
        results.append((combo, auc_pr))

# Ch·ªçn combo c√≥ mean AUC-PR cao nh·∫•t
best_combo = max(results, key=lambda x: mean(x[1]))</pre>
          </div>
          <p class="muted">‚úì Total: 9 combos √ó 3 folds = 27 training runs (~2.5 hours)</p>
          <p class="muted">‚úì Evaluation: AUC-PR (average_precision metric)</p>
        </div>

        <div class="workflow-step">
          <h4>Step 5: Final Training v·ªõi Best Params</h4>
          <div class="code-block">
            <pre># Apply best hyperparameters
best_params = {
    "numLeaves": 100,
    "learningRate": 0.15,
    "minDataInLeaf": 50,
    "featureFraction": 0.75,
    "baggingFraction": 0.75,
    "lambdaL1": 0.1,
    "lambdaL2": 0.1
}

# Train tr√™n full training data (4.5M samples)
from synapse.ml.lightgbm import LightGBMClassifier
lgbm = LightGBMClassifier(
    featuresCol="features",
    labelCol="is_helpful",
    **best_params
)
final_model = lgbm.fit(train_df)</pre>
          </div>
          <p class="muted">‚úì SynapseML LightGBM: distributed training tr√™n Spark</p>
          <p class="muted">‚úì Retrain v·ªõi best params ‚Üí generalization t·ªët h∆°n single fold</p>
        </div>

        <div class="workflow-step">
          <h4>Step 6: Evaluation & Save Model</h4>
          <div class="code-block">
            <pre># Predict tr√™n validation set
predictions = final_model.transform(val_df)

# Extract probability t·ª´ vector column
from pyspark.sql.functions import udf
prob_udf = udf(lambda v: float(v[1]), DoubleType())
predictions = predictions.withColumn("prob", prob_udf("probability"))

# Compute metrics
from sklearn.metrics import average_precision_score
y_true = predictions.select("is_helpful").toPandas().values
y_prob = predictions.select("prob").toPandas().values
auc_pr = average_precision_score(y_true, y_prob)  # 0.6315

# Save model to HDFS
final_model.write().overwrite().save(
    "hdfs://localhost:9000/output_v2/models/lightgbm_v7_auto"
)</pre>
          </div>
          <p class="muted">‚úì Model format: Spark MLlib pipeline (metadata + LightGBM booster)</p>
          <p class="muted">‚úì Metrics: AUC-PR, AUC-ROC, confusion matrix ‚Üí reports/*.json</p>
        </div>
      </div>
    </div>

    <!-- Auto-Tuning Results -->
    <div class="card card-full">
      <h2>üèÜ Auto-Tuning Results - Top 5 Configurations</h2>
      <table>
        <thead>
          <tr><th>Rank</th><th>Mean CV AUC-PR</th><th>Std Dev</th><th>numLeaves</th><th>learningRate</th></tr>
        </thead>
        <tbody>
          <tr style="background:#d1fae5">
            <td><strong>ü•á 1st</strong></td>
            <td><strong>0.6417</strong></td>
            <td>¬±0.0008</td>
            <td>100</td>
            <td>0.15</td>
          </tr>
          <tr>
            <td>ü•à 2nd</td>
            <td>0.6398</td>
            <td>¬±0.0015</td>
            <td>100</td>
            <td>0.10</td>
          </tr>
          <tr>
            <td>ü•â 3rd</td>
            <td>0.6387</td>
            <td>¬±0.0003</td>
            <td>100</td>
            <td>0.05</td>
          </tr>
          <tr>
            <td>4th</td>
            <td>0.6375</td>
            <td>¬±0.0020</td>
            <td>50</td>
            <td>0.15</td>
          </tr>
          <tr>
            <td>5th</td>
            <td>0.6374</td>
            <td>¬±0.0021</td>
            <td>50</td>
            <td>0.10</td>
          </tr>
        </tbody>
      </table>

      <div class="success-box" style="margin-top:16px">
        <strong>üí° Insight:</strong> numLeaves=100 consistently performs best across all learning rates. Higher learningRate (0.15) v·ªõi low variance (¬±0.0008) ‚Üí stable & optimal.
      </div>
    </div>

    <!-- Detailed Results -->
    <div class="grid">
      <div class="card">
        <h2>üìà Final Model Metrics (Best Params)</h2>
        <p class="muted">Trained v·ªõi numLeaves=100, learningRate=0.15:</p>
        <table>
          <thead>
            <tr><th>Metric</th><th>Value</th></tr>
          </thead>
          <tbody>
            <tr><td>Validation AUC-PR</td><td><strong>0.6315</strong></td></tr>
            <tr><td>Validation AUC-ROC</td><td><strong>0.8376</strong></td></tr>
            <tr><td>Precision</td><td><strong>80.79%</strong></td></tr>
            <tr><td>Recall</td><td><strong>56.84%</strong></td></tr>
            <tr><td>F1-Score</td><td><strong>58.70%</strong></td></tr>
          </tbody>
        </table>

        <h3>Confusion Matrix (Validation Set)</h3>
        <table>
          <thead>
            <tr><th></th><th>Predicted Neg</th><th>Predicted Pos</th></tr>
          </thead>
          <tbody>
            <tr><td><strong>Actual Neg</strong></td><td>169,012 (TN)</td><td>208,253 (FP)</td></tr>
            <tr><td><strong>Actual Pos</strong></td><td>7,881 (FN)</td><td>115,570 (TP)</td></tr>
          </tbody>
        </table>

        <div class="muted" style="margin-top:12px">
          <strong>Total Val Samples:</strong> 500,716 (10% of 5M training data)
        </div>
      </div>

      <div class="card">
        <h2>üìä Cross-Validation Analysis</h2>
        <p class="muted">Best configuration (numLeaves=100, lr=0.15) across 3 folds:</p>
        <table>
          <thead>
            <tr><th>Fold</th><th>AUC-PR</th><th>Samples</th></tr>
          </thead>
          <tbody>
            <tr><td>Fold 1/3</td><td>0.6424</td><td>~1.5M</td></tr>
            <tr><td>Fold 2/3</td><td>0.6407</td><td>~1.5M</td></tr>
            <tr><td>Fold 3/3</td><td>0.6419</td><td>~1.5M</td></tr>
            <tr style="background:#f3f4f6"><td><strong>Mean ¬± Std</strong></td><td><strong>0.6417 ¬± 0.0008</strong></td><td>4.5M total</td></tr>
          </tbody>
        </table>

        <div class="success-box" style="margin-top:16px">
          <strong>‚úì Low variance (¬±0.0008):</strong> Model stable, kh√¥ng b·ªã overfitting specific fold. Generalization t·ªët!
        </div>
      </div>
    </div>

    <!-- Training Configuration -->
    <div class="card card-full">
      <h2>‚öôÔ∏è Training Configuration Details</h2>
      <div class="grid" style="grid-template-columns:1fr 1fr">
        <div>
          <h3>Dataset Statistics</h3>
          <table>
            <tbody>
              <tr><td>Total Available</td><td>15,593,034 samples</td></tr>
              <tr><td>Training Used</td><td>5,000,000 samples (32%)</td></tr>
              <tr><td>Train Split</td><td>4,499,284 (90%)</td></tr>
              <tr><td>Val Split</td><td>500,716 (10%)</td></tr>
              <tr><td>Test Set</td><td>1,735,280 samples</td></tr>
              <tr><td>Feature Dimension</td><td>10,017 (10K TF-IDF + 17 numeric)</td></tr>
            </tbody>
          </table>
        </div>
        <div>
          <h3>LightGBM Parameters</h3>
          <table>
            <tbody>
              <tr><td>numLeaves</td><td>100 (best from tuning)</td></tr>
              <tr><td>learningRate</td><td>0.15 (best from tuning)</td></tr>
              <tr><td>minDataInLeaf</td><td>50</td></tr>
              <tr><td>featureFraction</td><td>0.75 (75% features/tree)</td></tr>
              <tr><td>baggingFraction</td><td>0.75 (75% samples/iter)</td></tr>
              <tr><td>lambdaL1 (L1 reg)</td><td>0.1</td></tr>
              <tr><td>lambdaL2 (L2 reg)</td><td>0.1</td></tr>
              <tr><td>Class Weight</td><td>3.054 (auto-computed)</td></tr>
            </tbody>
          </table>
        </div>
      </div>

      <div class="note" style="margin-top:16px">
        <strong>üí° Why limit to 5M samples?</strong><br>
        Training v·ªõi full 15.6M samples takes 8-10 hours. V·ªõi deadline 12 gi·ªù, ch·ªçn 5M samples (32%) ƒë·ªÉ:
        <ul style="margin:8px 0">
          <li>‚úì Auto-tuning ho√†n th√†nh trong 2.5 gi·ªù (9 combos √ó 3 folds)</li>
          <li>‚úì ƒê·ªß data cho model h·ªçc patterns (5M >> 1M baseline V6)</li>
          <li>‚úì C√≤n th·ªùi gian cho prediction & submission (1-2 gi·ªù)</li>
        </ul>
      </div>
    </div>

    <!-- Feature Importance -->
    <div class="card card-full">
      <h2>üéØ Feature Analysis (10,017 Features)</h2>
      <p>Model s·ª≠ d·ª•ng <strong>10,017 features</strong> t·ª´ feature_pipeline_v2:</p>
      
      <h3>Feature Breakdown:</h3>
      <table>
        <thead>
          <tr><th>Category</th><th>Count</th><th>Examples</th><th>Purpose</th></tr>
        </thead>
        <tbody>
          <tr>
            <td><strong>TF-IDF Text Features</strong></td>
            <td>10,000</td>
            <td>tf_awesome, tf_love, tf_great, tf_waste, tf_terrible, ...</td>
            <td>Capture semantic meaning t·ª´ review text (unigrams)</td>
          </tr>
          <tr>
            <td><strong>Numeric Features</strong></td>
            <td>17</td>
            <td>review_length, star_rating, user_review_count, product_avg_rating, ...</td>
            <td>Metadata v·ªÅ user, product, review quality</td>
          </tr>
        </tbody>
      </table>

      <h3>Top 10 Numeric Features (by importance):</h3>
      <table>
        <thead>
          <tr><th>Rank</th><th>Feature</th><th>Type</th><th>Explanation</th></tr>
        </thead>
        <tbody>
          <tr>
            <td>1</td>
            <td><code>user_helpful_ratio</code></td>
            <td>User behavior</td>
            <td>% helpful reviews c·ªßa user - signal m·∫°nh nh·∫•t</td>
          </tr>
          <tr>
            <td>2</td>
            <td><code>product_helpful_ratio</code></td>
            <td>Product aggregate</td>
            <td>% helpful reviews c·ªßa product - ch·∫•t l∆∞·ª£ng product</td>
          </tr>
          <tr>
            <td>3</td>
            <td><code>review_length</code></td>
            <td>Review quality</td>
            <td>S·ªë k√Ω t·ª± - reviews d√†i th∆∞·ªùng informative h∆°n</td>
          </tr>
          <tr>
            <td>4</td>
            <td><code>star_rating</code></td>
            <td>Review quality</td>
            <td>1-5 stars - extreme ratings (1 or 5) thu h√∫t votes</td>
          </tr>
          <tr>
            <td>5</td>
            <td><code>user_review_count</code></td>
            <td>User behavior</td>
            <td>S·ªë reviews c·ªßa user - experienced reviewers ƒë√°ng tin</td>
          </tr>
          <tr>
            <td>6</td>
            <td><code>product_review_count</code></td>
            <td>Product aggregate</td>
            <td>S·ªë reviews c·ªßa product - popularity indicator</td>
          </tr>
          <tr>
            <td>7</td>
            <td><code>user_avg_rating</code></td>
            <td>User behavior</td>
            <td>Average rating c·ªßa user - harsh vs lenient reviewer</td>
          </tr>
          <tr>
            <td>8</td>
            <td><code>product_avg_rating</code></td>
            <td>Product aggregate</td>
            <td>Average rating c·ªßa product - quality signal</td>
          </tr>
          <tr>
            <td>9</td>
            <td><code>review_length_log</code></td>
            <td>Review quality</td>
            <td>log(review_length) - normalize skewed distribution</td>
          </tr>
          <tr>
            <td>10</td>
            <td><code>rating_deviation</code></td>
            <td>Review quality</td>
            <td>|user_rating - product_avg_rating| - controversial reviews</td>
          </tr>
        </tbody>
      </table>

      <div class="note" style="margin-top:16px">
        <strong>üí° Feature Importance Insight:</strong><br>
        - <strong>User behavior</strong> (helpful_ratio, review_count) l√† predictors m·∫°nh nh·∫•t<br>
        - <strong>Product aggregates</strong> (helpful_ratio, avg_rating) c≈©ng r·∫•t quan tr·ªçng<br>
        - <strong>TF-IDF features</strong> (10K terms) capture semantic meaning nh∆∞ng individual weight th·∫•p (spread across many terms)<br>
        - <strong>Review quality</strong> (length, rating) l√† moderate predictors
      </div>
    </div>

    <!-- Training Timeline -->
    <div class="card card-full">
      <h2>‚è±Ô∏è Training Timeline & Performance</h2>
      <table>
        <thead>
          <tr><th>Phase</th><th>Duration</th><th>Operations</th><th>Result</th></tr>
        </thead>
        <tbody>
          <tr>
            <td><strong>Data Loading</strong></td>
            <td>~2 min</td>
            <td>Load 15.6M samples t·ª´ HDFS, limit to 5M, split 90/10</td>
            <td>‚úì 4.5M train, 500K val</td>
          </tr>
          <tr>
            <td><strong>Grid Search CV</strong></td>
            <td>~2.5 hours</td>
            <td>9 combos √ó 3 folds = 27 training runs</td>
            <td>‚úì Best: numLeaves=100, lr=0.15</td>
          </tr>
          <tr>
            <td><strong>Final Training</strong></td>
            <td>~5 min</td>
            <td>Retrain v·ªõi best params tr√™n 4.5M samples</td>
            <td>‚úì Val AUC-PR: 0.6315</td>
          </tr>
          <tr>
            <td><strong>Model Saving</strong></td>
            <td>~30 sec</td>
            <td>Save to HDFS + generate reports (JSON/CSV/TXT)</td>
            <td>‚úì Model at lightgbm_v7_auto</td>
          </tr>
          <tr style="background:#f3f4f6">
            <td><strong>Total</strong></td>
            <td><strong>~2h 40m</strong></td>
            <td>Start: 16:04, End: 18:50</td>
            <td><strong>‚úì Auto-tuning Complete</strong></td>
          </tr>
        </tbody>
      </table>

      <div class="success-box" style="margin-top:16px">
        <strong>üéØ Efficiency:</strong> Auto-tuning ho√†n th√†nh trong 2.7 gi·ªù (thay v√¨ 8-10 gi·ªù v·ªõi full data). ƒê·ªß th·ªùi gian cho prediction & submission trong deadline 12 gi·ªù!
      </div>
    </div>

    <!-- Key Learnings -->
    <div class="card card-full">
      <h2>ÔøΩ Key Learnings & Insights</h2>
      
      <h3>1Ô∏è‚É£ Auto-Tuning Effectiveness</h3>
      <div class="feature-list">
        <p><strong>‚úì Systematic Search:</strong> Grid search t√¨m ƒë∆∞·ª£c optimal params (numLeaves=100, lr=0.15) m√† manual tuning kh√≥ ph√°t hi·ªán.</p>
        <p><strong>‚úì Cross-Validation:</strong> 3-fold CV v·ªõi low variance (¬±0.0008) ‚Üí model stable, kh√¥ng b·ªã overfitting.</p>
        <p><strong>‚úì numLeaves Impact:</strong> 100 leaves consistently outperforms 31 & 50 ‚Üí model c·∫ßn complexity ƒë·ªÉ h·ªçc 10K features.</p>
        <p><strong>‚úì Learning Rate:</strong> 0.15 (highest tested) cho best result ‚Üí faster convergence v·ªõi regularization ƒë·ªß m·∫°nh.</p>
      </div>

      <h3>2Ô∏è‚É£ Data Strategy</h3>
      <div class="feature-list">
        <p><strong>‚ö†Ô∏è More Data ‚â† Always Better:</strong> V7 v·ªõi 5M samples (AUC-PR 0.6315) kh√¥ng t·ªët h∆°n V6 v·ªõi 1M samples (AUC-PR 0.6444).</p>
        <p><strong>Hypothesis:</strong> 5M samples c√≥ nhi·ªÅu noise h∆°n ‚Üí model h·ªçc c·∫£ patterns l·∫´n noise.</p>
        <p><strong>Trade-off:</strong> 5M samples ƒë·ªß cho auto-tuning nhanh (2.7h) nh∆∞ng performance kh√¥ng optimal.</p>
        <p><strong>Next Step:</strong> Th·ª≠ 2-3M samples v·ªõi best params ‚Üí balance gi·ªØa data quality & quantity.</p>
      </div>

      <h3>3Ô∏è‚É£ Feature Engineering Impact</h3>
      <div class="feature-list">
        <p><strong>TF-IDF Dominance:</strong> 10K text features chi·∫øm 99.8% feature space ‚Üí capture semantic meaning t·ªët.</p>
        <p><strong>Metadata Power:</strong> 17 numeric features (0.2%) nh∆∞ng c√≥ predictive power cao (user_helpful_ratio, product_helpful_ratio).</p>
        <p><strong>Combination Effect:</strong> Text + metadata synergy ‚Üí model h·ªçc c·∫£ content l·∫´n context.</p>
      </div>

      <h3>4Ô∏è‚É£ Class Imbalance Handling</h3>
      <div class="feature-list">
        <p><strong>Effective Weight:</strong> Scale pos weight = 3.054 ‚Üí balance loss function cho imbalanced data.</p>
        <p><strong>Stratified CV:</strong> Gi·ªØ ratio 1:3 trong m·ªçi fold ‚Üí reliable validation metrics.</p>
        <p><strong>Metric Choice:</strong> AUC-PR (kh√¥ng ph·∫£i accuracy) ‚Üí ph√π h·ª£p v·ªõi imbalanced classification.</p>
      </div>
    </div>

    <!-- Model Comparison -->
    <div class="card card-full">
      <h2>üìä Model Version Comparison</h2>
      <table>
        <thead>
          <tr><th>Version</th><th>Training Samples</th><th>numLeaves</th><th>learningRate</th><th>Val AUC-PR</th><th>Notes</th></tr>
        </thead>
        <tbody>
          <tr>
            <td>V4</td>
            <td>1M</td>
            <td>128</td>
            <td>0.035</td>
            <td><strong>0.6448</strong></td>
            <td>Manual tuning, small data</td>
          </tr>
          <tr>
            <td>V5</td>
            <td>1M</td>
            <td>50</td>
            <td>0.05</td>
            <td>0.6363</td>
            <td>Underfit (too simple)</td>
          </tr>
          <tr>
            <td>V6</td>
            <td>1M</td>
            <td>100</td>
            <td>0.03</td>
            <td><strong>0.6444</strong></td>
            <td>Balanced complexity</td>
          </tr>
          <tr>
            <td>V7 Manual</td>
            <td>5M</td>
            <td>120</td>
            <td>0.03</td>
            <td>0.6327</td>
            <td>‚ùå More data but worse (noise)</td>
          </tr>
          <tr style="background:#d1fae5">
            <td><strong>V7 Auto-Tune</strong></td>
            <td><strong>5M</strong></td>
            <td><strong>100</strong></td>
            <td><strong>0.15</strong></td>
            <td><strong>0.6315</strong></td>
            <td><strong>‚úì Best params from CV</strong></td>
          </tr>
        </tbody>
      </table>

      <div class="note" style="margin-top:16px">
        <strong>‚ö†Ô∏è Performance Paradox:</strong><br>
        - V4/V6 (1M samples) ƒë·∫°t 0.644-0.645 AUC-PR<br>
        - V7 (5M samples) ch·ªâ ƒë·∫°t 0.631-0.633 AUC-PR<br>
        - <strong>Conclusion:</strong> More data kh√¥ng ƒë·∫£m b·∫£o better model. Data quality > data quantity. 5M samples c√≥ nhi·ªÅu noise/outliers ‚Üí model h·ªçc patterns + noise.
      </div>

      <h3>Best Configuration (from Auto-Tuning):</h3>
      <div class="feature-list">
        <ul>
          <li><code>numLeaves = 100</code> ‚Üí Optimal complexity cho 10K features</li>
          <li><code>learningRate = 0.15</code> ‚Üí Fast convergence v·ªõi regularization</li>
          <li><code>minDataInLeaf = 50</code> ‚Üí Prevent overfitting</li>
          <li><code>featureFraction = 0.75</code> ‚Üí Random feature selection</li>
          <li><code>baggingFraction = 0.75</code> ‚Üí Bagging for stability</li>
          <li><code>lambdaL1 = 0.1, lambdaL2 = 0.1</code> ‚Üí Regularization</li>
        </ul>
      </div>
    </div>

    <!-- LightGBM Parameters Detailed -->
    <div class="card card-full">
      <h2>‚öôÔ∏è LightGBM Hyperparameters - Chi Ti·∫øt</h2>
      <p>Gi·∫£i th√≠ch t·ª´ng hyperparameter trong LightGBMClassifier:</p>

      <table>
        <thead>
          <tr><th>Parameter</th><th>Value</th><th>√ù Nghƒ©a</th><th>Trade-off</th></tr>
        </thead>
        <tbody>
          <tr>
            <td><strong>numLeaves</strong></td>
            <td>100</td>
            <td>S·ªë l√° t·ªëi ƒëa m·ªói c√¢y. C√†ng cao ‚Üí c√¢y ph·ª©c t·∫°p h∆°n ‚Üí h·ªçc patterns chi ti·∫øt h∆°n</td>
            <td>High: overfitting risk | Low: underfitting (too simple)</td>
          </tr>
          <tr>
            <td><strong>learningRate</strong></td>
            <td>0.15</td>
            <td>Step size trong gradient descent. M·ªói c√¢y ƒë√≥ng g√≥p learningRate √ó prediction v√†o t·ªïng</td>
            <td>High: fast convergence, overfitting | Low: slow, better generalization</td>
          </tr>
          <tr>
            <td><strong>numIterations</strong></td>
            <td>1500</td>
            <td>S·ªë c√¢y t·ªëi ƒëa (boosting rounds). C√†ng nhi·ªÅu ‚Üí model m·∫°nh h∆°n nh∆∞ng risk overfit</td>
            <td>High: powerful but overfit | Low: underfit (not enough trees)</td>
          </tr>
          <tr>
            <td><strong>earlyStoppingRound</strong></td>
            <td>200</td>
            <td>D·ª´ng training n·∫øu validation metric kh√¥ng c·∫£i thi·ªán sau 200 rounds ‚Üí prevent overfit</td>
            <td>High: more patient (may overfit) | Low: stop too early (underfit)</td>
          </tr>
          <tr>
            <td><strong>minDataInLeaf</strong></td>
            <td>50</td>
            <td>S·ªë samples t·ªëi thi·ªÉu m·ªói l√°. C√†ng cao ‚Üí c√¢y t·ªïng qu√°t h∆°n, √≠t overfit h∆°n</td>
            <td>High: generalization, underfit | Low: specific, overfit</td>
          </tr>
          <tr>
            <td><strong>featureFraction</strong></td>
            <td>0.75</td>
            <td>Random ch·ªçn 75% features m·ªói iteration. Gi·∫£m correlation gi·ªØa c√°c c√¢y ‚Üí ensemble t·ªët h∆°n</td>
            <td>High: use more features | Low: more randomness, prevent overfit</td>
          </tr>
          <tr>
            <td><strong>baggingFraction</strong></td>
            <td>0.75</td>
            <td>Random sample 75% data m·ªói iteration (bagging). TƒÉng diversity ‚Üí robust model</td>
            <td>High: use more data | Low: more bagging, prevent overfit</td>
          </tr>
          <tr>
            <td><strong>maxDepth</strong></td>
            <td>-1</td>
            <td>Max tree depth (-1 = unlimited). Limit depth ‚Üí simpler trees ‚Üí less overfit</td>
            <td>High/unlimited: complex trees | Low: simple, generalization</td>
          </tr>
          <tr>
            <td><strong>lambdaL1</strong></td>
            <td>0.1</td>
            <td>L1 regularization (Lasso). Penalize sum of absolute weights ‚Üí feature selection (sparse)</td>
            <td>High: strong penalty, sparse | Low: weak penalty, use all features</td>
          </tr>
          <tr>
            <td><strong>lambdaL2</strong></td>
            <td>0.1</td>
            <td>L2 regularization (Ridge). Penalize sum of squared weights ‚Üí weight decay (smooth)</td>
            <td>High: strong penalty, smooth | Low: weak penalty, large weights OK</td>
          </tr>
          <tr>
            <td><strong>objective</strong></td>
            <td>binary</td>
            <td>Binary classification v·ªõi log loss (binary cross-entropy)</td>
            <td>N/A (task-specific)</td>
          </tr>
          <tr>
            <td><strong>isUnbalance</strong></td>
            <td>True</td>
            <td>Enable imbalance handling (auto adjust positive weight d·ª±a tr√™n class distribution)</td>
            <td>True: handle imbalance | False: treat equally</td>
          </tr>
          <tr>
            <td><strong>classWeight</strong></td>
            <td>"0:1,1:3.054"</td>
            <td>Manual class weights. Class 0 (neg) weight=1, Class 1 (pos) weight=3.054</td>
            <td>High pos weight: focus on minority | Equal: no imbalance handling</td>
          </tr>
        </tbody>
      </table>

      <h3>C√¥ng Th·ª©c Loss Function (Binary Cross-Entropy)</h3>
      <div class="code-block">
        <pre># Binary Cross-Entropy v·ªõi class weights
Loss = - (1/N) √ó Œ£ [w_i √ó y_i √ó log(p_i) + (1 - y_i) √ó log(1 - p_i)]

where:
  N = s·ªë samples
  y_i = ground truth label (0 ho·∫∑c 1)
  p_i = predicted probability (sigmoid output)
  w_i = sample weight (pos: 3.054, neg: 1.0)

# Effect c·ªßa class weight:
- Positive samples (y=1): loss nh√¢n v·ªõi 3.054 ‚Üí model focus h∆°n
- Negative samples (y=0): loss nh√¢n v·ªõi 1.0 ‚Üí ·∫£nh h∆∞·ªüng b√¨nh th∆∞·ªùng</pre>
      </div>

      <h3>Regularization Explained</h3>
      <div class="feature-list">
        <p><strong>L1 Regularization (Lasso):</strong></p>
        <div class="code-block">
          <pre>Loss_total = Loss + Œª‚ÇÅ √ó Œ£|w_i|

Effect: 
- Penalize absolute values c·ªßa weights
- Force weights v·ªÅ 0 ‚Üí feature selection (sparse model)
- Useful khi c√≥ nhi·ªÅu features kh√¥ng quan tr·ªçng (10K TF-IDF)</pre>
        </div>

        <p><strong>L2 Regularization (Ridge):</strong></p>
        <div class="code-block">
          <pre>Loss_total = Loss + Œª‚ÇÇ √ó Œ£(w_i)¬≤

Effect:
- Penalize squared values c·ªßa weights
- Shrink weights v·ªÅ g·∫ßn 0 (kh√¥ng v·ªÅ ƒë√∫ng 0)
- Prefer small, distributed weights ‚Üí smooth model</pre>
        </div>

        <p><strong>Combined (Elastic Net):</strong></p>
        <div class="code-block">
          <pre>Loss_total = Loss + Œª‚ÇÅ √ó Œ£|w_i| + Œª‚ÇÇ √ó Œ£(w_i)¬≤

lambdaL1=0.1, lambdaL2=0.1 ‚Üí mild regularization
- Balance gi·ªØa feature selection (L1) v√† weight smoothing (L2)
- Prevent overfitting v·ªõi 10K features</pre>
        </div>
      </div>

      <h3>Gradient Descent trong LightGBM</h3>
      <div class="code-block">
        <pre># Additive model (boosting)
F_m(x) = F_(m-1)(x) + Œ∑ √ó h_m(x)

where:
  F_m(x) = prediction sau m trees
  Œ∑ = learningRate (0.15)
  h_m(x) = c√¢y th·ª© m (h·ªçc t·ª´ residual/gradient)

# Training process:
1. Initialize: F_0(x) = log(pos/neg) = log(1,109,945 / 3,389,339)
2. For m = 1 to numIterations (1500):
     a. Compute gradient: g_i = ‚àÇLoss/‚àÇF_(m-1)(x_i)
     b. Build tree h_m(x) to fit gradient g
     c. Update: F_m(x) = F_(m-1)(x) + 0.15 √ó h_m(x)
     d. Check early stopping (AUC-PR kh√¥ng tƒÉng sau 200 rounds)
3. Final prediction: p = sigmoid(F_1500(x))</pre>
      </div>

      <div class="success-box" style="margin-top:16px">
        <strong>üéØ T√≥m t·∫Øt Best Config:</strong><br>
        - <strong>numLeaves=100, lr=0.15:</strong> Balance gi·ªØa complexity v√† generalization<br>
        - <strong>featureFraction=0.75, baggingFraction=0.75:</strong> Random subsampling ‚Üí ensemble diversity<br>
        - <strong>lambdaL1=0.1, lambdaL2=0.1:</strong> Mild regularization ‚Üí prevent overfit 10K features<br>
        - <strong>classWeight=3.054:</strong> Handle 1:3 imbalance ‚Üí focus on minority class<br>
        - <strong>earlyStoppingRound=200:</strong> Automatic stop khi validation plateau
      </div>
    </div>

    <!-- Output Files -->
    <div class="card card-full">
      <h2>üìÅ Output Artifacts</h2>
      
      <h3>Model Files (HDFS)</h3>
      <table>
        <thead>
          <tr><th>Path</th><th>Description</th><th>Usage</th></tr>
        </thead>
        <tbody>
          <tr>
            <td><code>hdfs://.../lightgbm_v7_auto/</code></td>
            <td>Spark MLlib LightGBM model (directory)</td>
            <td>Load trong predict_pipeline_v2.py</td>
          </tr>
          <tr>
            <td><code>hdfs://.../lightgbm_v7_auto/metadata/</code></td>
            <td>Model metadata (schema, params)</td>
            <td>Spark pipeline metadata</td>
          </tr>
          <tr>
            <td><code>hdfs://.../lightgbm_v7_auto/stages/</code></td>
            <td>Pipeline stages (LightGBM booster)</td>
            <td>Actual model weights & trees</td>
          </tr>
        </tbody>
      </table>

      <h3>Training Reports (Local)</h3>
      <table>
        <thead>
          <tr><th>File</th><th>Description</th><th>Content</th></tr>
        </thead>
        <tbody>
          <tr>
            <td><code>training_report_20251101_185019.json</code></td>
            <td>Comprehensive training report (JSON)</td>
            <td>Hyperparameters, metrics, confusion matrix, CV results</td>
          </tr>
          <tr>
            <td><code>training_report_20251101_185019_metrics.csv</code></td>
            <td>Metrics table (CSV format)</td>
            <td>AUC-PR, AUC-ROC, Precision, Recall, F1 per fold</td>
          </tr>
          <tr>
            <td><code>training_report_20251101_185019_summary.txt</code></td>
            <td>Human-readable summary (TXT)</td>
            <td>Executive summary, best params, top configs</td>
          </tr>
        </tbody>
      </table>

      <div class="note" style="margin-top:16px">
        <strong>üìù Report Contents:</strong><br>
        - <strong>CV Results:</strong> 9 configs √ó 3 folds = 27 AUC-PR scores<br>
        - <strong>Best Params:</strong> numLeaves=100, learningRate=0.15<br>
        - <strong>Final Metrics:</strong> Val AUC-PR=0.6315, Precision=80.79%, Recall=56.84%<br>
        - <strong>Confusion Matrix:</strong> TP=115,570, TN=169,012, FP=208,253, FN=7,881<br>
        - <strong>Training Info:</strong> 5M samples, 10,017 features, class weight=3.054
      </div>
    </div>

    <!-- Next Steps -->
    <div class="card card-full">
      <h2>üöÄ Next Steps - Prediction & Submission</h2>
      
      <div class="success-box">
        <strong>‚úÖ Auto-Tuning HO√ÄN TH√ÄNH!</strong><br>
        Best hyperparameters ƒë√£ t√¨m ƒë∆∞·ª£c: <strong>numLeaves=100, learningRate=0.15</strong>. Model trained v√† saved t·∫°i HDFS. B∆∞·ªõc ti·∫øp theo: Run prediction tr√™n test set ‚Üí Generate submission.csv ‚Üí Submit!
      </div>

      <h3>üìã Step 1: Run Prediction Pipeline</h3>
      
      <div class="code-block">
        <pre># Ch·∫°y inference v·ªõi model V7 auto-tuned
spark-submit \
  --master local[*] \
  --packages com.microsoft.azure:synapseml-lightgbm_2.12:1.0.7 \
  --driver-memory 11g \
  --executor-memory 11g \
  "code_v2/models/predict_pipeline_v2.py" \
  --model_path "hdfs://localhost:9000/output_v2/models/lightgbm_v7_auto" \
  --test "hdfs://localhost:9000/output_v2/features_test_v4" \
  --out "hdfs://localhost:9000/output_v2/predictions_v7_auto" \
  --debug_samples 100

# Download submission.csv t·ª´ HDFS
hdfs dfs -get hdfs://localhost:9000/output_v2/predictions_v7_auto/submission.csv \
  output/submission_v7_auto.csv</pre>
      </div>

      <h3>‚úÖ Validation Checklist</h3>
      <ul>
        <li>‚úì <strong>Row Count:</strong> 1,735,280 rows (= test set size)</li>
        <li>‚úì <strong>Columns:</strong> review_id (string), probability_helpful (double)</li>
        <li>‚úì <strong>No NULLs:</strong> All predictions valid</li>
        <li>‚úì <strong>Probability Range:</strong> [0.0, 1.0] (sigmoid output)</li>
        <li>‚úì <strong>Format:</strong> CSV with header</li>
      </ul>

      <h3>üìä Decision: V7 Baseline vs V7 Auto-Tune</h3>
      <table>
        <thead>
          <tr><th>Model</th><th>Val AUC-PR</th><th>Params</th><th>Status</th></tr>
        </thead>
        <tbody>
          <tr>
            <td>V7 Baseline (Manual)</td>
            <td>0.6327</td>
            <td>numLeaves=120, lr=0.03</td>
            <td>‚úì Submission ready</td>
          </tr>
          <tr style="background:#d1fae5">
            <td><strong>V7 Auto-Tune</strong></td>
            <td><strong>0.6315</strong></td>
            <td><strong>numLeaves=100, lr=0.15</strong></td>
            <td><strong>‚è≥ Need prediction</strong></td>
          </tr>
        </tbody>
      </table>

      <div class="note" style="margin-top:16px">
        <strong>ü§î Which to Submit?</strong><br>
        - V7 Baseline: AUC-PR 0.6327 (slightly better validation)<br>
        - V7 Auto-Tune: AUC-PR 0.6315 (from CV, more robust)<br>
        <br>
        <strong>Recommendation:</strong> Submit <strong>V7 Baseline (submission_v7.csv)</strong> v√¨:
        <ul>
          <li>‚úì Higher validation AUC-PR (0.6327 > 0.6315)</li>
          <li>‚úì Already generated & validated</li>
          <li>‚úì Save time (auto-tune prediction takes ~10 min)</li>
        </ul>
        <br>
        <strong>Alternative:</strong> Generate V7 Auto-Tune prediction ‚Üí compare probability distributions ‚Üí submit better one.
      </div>

      <h3>üéØ Expected Timeline</h3>
      <table>
        <thead>
          <tr><th>Task</th><th>Duration</th><th>Action</th></tr>
        </thead>
        <tbody>
          <tr><td>Run Prediction (V7 Auto)</td><td>~10 min</td><td>spark-submit predict_pipeline_v2.py</td></tr>
          <tr><td>Download CSV</td><td>~1 min</td><td>hdfs dfs -get submission.csv</td></tr>
          <tr><td>Compare Models</td><td>~5 min</td><td>Check prob distributions, stats</td></tr>
          <tr><td>Final Submission</td><td>~5 min</td><td>Upload to competition platform</td></tr>
          <tr style="background:#f3f4f6"><td><strong>Total</strong></td><td><strong>~20 min</strong></td><td><strong>Complete pipeline</strong></td></tr>
        </tbody>
      </table>
    </div>

    <!-- Summary Box -->
    <div class="card card-full" style="background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:#fff">
      <h2 style="color:#fff;border-bottom:3px solid #fff">üéì T√≥m T·∫Øt K·ªπ Thu·∫≠t</h2>
      
      <div style="display:grid;grid-template-columns:1fr 1fr;gap:20px;margin-top:16px">
        <div>
          <h3 style="color:#fff">Thu·∫≠t To√°n</h3>
          <ul style="color:#fff">
            <li><strong>LightGBM:</strong> Gradient Boosting v·ªõi histogram-based learning</li>
            <li><strong>Grid Search:</strong> 9 combinations (3√ó3 grid)</li>
            <li><strong>3-Fold CV:</strong> Stratified cross-validation (27 runs)</li>
            <li><strong>Loss Function:</strong> Binary cross-entropy</li>
            <li><strong>Optimization:</strong> Gradient descent with L1/L2 regularization</li>
          </ul>
        </div>
        <div>
          <h3 style="color:#fff">K·ªπ Thu·∫≠t</h3>
          <ul style="color:#fff">
            <li><strong>Distributed Training:</strong> PySpark + SynapseML LightGBM</li>
            <li><strong>Class Imbalance:</strong> Scale pos weight = 3.054</li>
            <li><strong>Feature Engineering:</strong> TF-IDF (10K) + Metadata (17)</li>
            <li><strong>Data Strategy:</strong> Limit 5M/15.6M samples (time optimization)</li>
            <li><strong>Evaluation:</strong> AUC-PR (ph√π h·ª£p v·ªõi imbalanced data)</li>
          </ul>
        </div>
      </div>

      <div style="margin-top:20px;padding:16px;background:rgba(255,255,255,0.2);border-radius:8px">
        <strong style="font-size:1.1em">üèÜ Best Hyperparameters:</strong><br>
        <code style="color:#fff">numLeaves=100 | learningRate=0.15 | minDataInLeaf=50 | featureFraction=0.75 | baggingFraction=0.75 | lambdaL1=0.1 | lambdaL2=0.1</code>
      </div>
    </div>

    <!-- Footer -->
    <div style="text-align:center;padding:24px;color:#fff;font-size:0.9em">
      <p><strong>Day 3 V2 Auto-Tuning Report</strong> ‚Äî Generated on November 1, 2025</p>
      <p>Authors: V√µ Th·ªã Di·ªÖm Thanh (Model Training) ‚Ä¢ L√™ ƒêƒÉng Ho√†ng Tu·∫•n (Infrastructure)</p>
      <p style="margin-top:8px">
        <span class="badge badge-success">CV AUC-PR: 0.6417</span>
        <span class="badge badge-info">Val AUC-PR: 0.6315</span>
        <span class="badge badge-info">27 Training Runs</span>
        <span class="badge badge-info">10,017 Features</span>
      </p>
    </div>
  </div>
</body>
</html>