<!DOCTYPE html>
<html lang="vi">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Day 3 V2 - Final Submission Report</title>
  <style>
    body{font-family:'Segoe UI',Tahoma,Arial,sans-serif;background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:#222;margin:0;padding:24px}
    .container{max-width:1400px;margin:0 auto}
    .hero{background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:#fff;border-radius:16px;padding:40px;margin-bottom:24px;box-shadow:0 20px 60px rgba(0,0,0,0.3)}
    .hero h1{margin:0 0 12px;font-size:2.5em;font-weight:700}
    .hero .subtitle{font-size:1.1em;opacity:0.9;margin:0}
    .grid{display:grid;grid-template-columns:repeat(auto-fit,minmax(350px,1fr));gap:20px;margin-bottom:20px}
    .card{background:#fff;border-radius:12px;padding:24px;box-shadow:0 8px 30px rgba(0,0,0,0.12);transition:transform 0.2s}
    .card:hover{transform:translateY(-4px);box-shadow:0 12px 40px rgba(0,0,0,0.15)}
    .card-full{grid-column:1/-1}
    h2{color:#667eea;margin:0 0 16px;font-size:1.5em;border-bottom:3px solid #667eea;padding-bottom:8px}
    h3{color:#333;margin:20px 0 12px;font-size:1.2em}
    .metric-grid{display:grid;grid-template-columns:repeat(auto-fit,minmax(200px,1fr));gap:16px;margin:16px 0}
    .metric-box{background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:#fff;padding:20px;border-radius:10px;text-align:center}
    .metric-box .label{font-size:0.9em;opacity:0.9;margin-bottom:8px}
    .metric-box .value{font-size:2em;font-weight:700}
    .code-block{background:#0d1117;color:#c9d1d9;padding:16px;border-radius:8px;overflow-x:auto;margin:12px 0;border-left:4px solid #667eea}
    .code-block pre{margin:0;font-family:'Consolas','Monaco','Courier New',monospace;font-size:0.9em}
    table{width:100%;border-collapse:collapse;margin:16px 0}
    th,td{padding:12px;text-align:left;border-bottom:1px solid #e5e7eb}
    th{background:#f3f4f6;color:#667eea;font-weight:600}
    tr:hover{background:#f9fafb}
    .badge{display:inline-block;padding:6px 12px;border-radius:20px;font-size:0.85em;font-weight:600;margin:4px}
    .badge-success{background:#d1fae5;color:#065f46}
    .badge-info{background:#dbeafe;color:#1e40af}
    .badge-warning{background:#fef3c7;color:#92400e}
    .badge-danger{background:#fee2e2;color:#991b1b}
    .success-box{background:#d1fae5;border-left:4px solid #10b981;padding:12px 16px;border-radius:4px;margin:12px 0}
    .warning-box{background:#fff3cd;border-left:4px solid #ffc107;padding:12px 16px;border-radius:4px;margin:12px 0}
    .info-box{background:#dbeafe;border-left:4px solid #3b82f6;padding:12px 16px;border-radius:4px;margin:12px 0}
    .compare-grid{display:grid;grid-template-columns:1fr 1fr;gap:20px;margin:20px 0}
  </style>
</head>
<body>
  <div class="container">
    <div class="hero">
      <h1>üéâ Day 3 V2 ‚Äî Final Submission Report</h1>
      <p class="subtitle">Auto-Tuning Complete + Predictions Generated</p>
      <div style="margin-top:16px">
        <span class="badge badge-info">Date: November 1, 2025</span>
        <span class="badge badge-success">Status: Ready for Submission ‚úì</span>
        <span class="badge badge-info">Models: V7 Baseline + V7 Auto-tune</span>
      </div>
    </div>

    <!-- Executive Summary -->
    <div class="card card-full">
      <h2>üìä Executive Summary</h2>
      <div class="success-box">
        <strong>üéØ Mission Complete!</strong><br>
        ƒê√£ ho√†n th√†nh training, auto-tuning, v√† prediction cho c·∫£ 2 models. S·∫µn s√†ng 2 submission files ƒë·ªÉ so s√°nh v√† ch·ªçn best model!
      </div>
      
      <div class="metric-grid">
        <div class="metric-box">
          <div class="label">Test Predictions</div>
          <div class="value">1.73M</div>
        </div>
        <div class="metric-box">
          <div class="label">Feature Dimension</div>
          <div class="value">10,017</div>
        </div>
        <div class="metric-box">
          <div class="label">Models Trained</div>
          <div class="value">2</div>
        </div>
        <div class="metric-box">
          <div class="label">Total Runtime</div>
          <div class="value">~6 hrs</div>
        </div>
      </div>
    </div>

    <!-- Model Comparison -->
    <div class="card card-full">
      <h2>‚öñÔ∏è V7 Baseline vs V7 Auto-tune Comparison</h2>
      
      <div class="compare-grid">
        <div>
          <h3>üìå V7 Baseline</h3>
          <div class="info-box">
            <strong>Manual Hyperparameters</strong><br>
            - numLeaves: 120<br>
            - learningRate: 0.03<br>
            - minDataInLeaf: 50
          </div>
          <table>
            <thead>
              <tr><th>Metric</th><th>Value</th></tr>
            </thead>
            <tbody>
              <tr><td><strong>Validation AUC-PR</strong></td><td><span class="badge badge-success">0.6327</span></td></tr>
              <tr><td>Validation AUC-ROC</td><td>0.8392</td></tr>
              <tr><td>Precision</td><td>81.59%</td></tr>
              <tr><td>Recall</td><td>57.67%</td></tr>
              <tr><td>F1-Score</td><td>67.55%</td></tr>
              <tr><td>Training Time</td><td>~2.5 hours</td></tr>
              <tr><td>File Size</td><td>53.77 MB</td></tr>
              <tr><td>Rows</td><td>1,735,281</td></tr>
            </tbody>
          </table>
        </div>

        <div>
          <h3>üîß V7 Auto-tune</h3>
          <div class="info-box">
            <strong>Best Auto-tuned Params</strong><br>
            - numLeaves: 100<br>
            - learningRate: 0.15<br>
            - minDataInLeaf: 50
          </div>
          <table>
            <thead>
              <tr><th>Metric</th><th>Value</th></tr>
            </thead>
            <tbody>
              <tr><td><strong>Validation AUC-PR</strong></td><td><span class="badge badge-warning">0.6315</span></td></tr>
              <tr><td>Validation AUC-ROC</td><td>0.8376</td></tr>
              <tr><td>Precision</td><td>80.79%</td></tr>
              <tr><td>Recall</td><td>56.84%</td></tr>
              <tr><td>F1-Score</td><td>66.76%</td></tr>
              <tr><td>Training Time</td><td>~2.7 hours (27 runs)</td></tr>
              <tr><td>File Size</td><td>53.74 MB</td></tr>
              <tr><td>Rows</td><td>1,735,281</td></tr>
            </tbody>
          </table>
        </div>
      </div>

      <div class="warning-box" style="margin-top:20px">
        <strong>‚ö†Ô∏è Analysis:</strong><br>
        - <strong>V7 Baseline WON</strong> by a narrow margin (+0.0012 AUC-PR)<br>
        - Baseline: 0.6327 vs Auto-tune: 0.6315 (difference: 0.19%)<br>
        - Manual hyperparameters (numLeaves=120, lr=0.03) slightly better than auto-tuned (numLeaves=100, lr=0.15)<br>
        - Both models very close in performance ‚Üí recommend testing both on leaderboard
      </div>
    </div>

    <!-- Prediction Statistics -->
    <div class="card card-full">
      <h2>üìà V7 Auto-tune Prediction Statistics</h2>
      
      <table>
        <thead>
          <tr><th>Metric</th><th>Value</th><th>Description</th></tr>
        </thead>
        <tbody>
          <tr>
            <td><strong>Test Samples</strong></td>
            <td>1,735,280</td>
            <td>Total predictions generated</td>
          </tr>
          <tr>
            <td><strong>Feature Dimension</strong></td>
            <td>10,017</td>
            <td>10K TF-IDF + 17 numeric features</td>
          </tr>
          <tr>
            <td><strong>Min Probability</strong></td>
            <td>0.3467</td>
            <td>Lowest helpful probability</td>
          </tr>
          <tr>
            <td><strong>Max Probability</strong></td>
            <td>0.6792</td>
            <td>Highest helpful probability</td>
          </tr>
          <tr>
            <td><strong>Mean Probability</strong></td>
            <td>0.5729</td>
            <td>Average helpful probability</td>
          </tr>
          <tr>
            <td><strong>Std Deviation</strong></td>
            <td>0.0773</td>
            <td>Low variance (tight distribution)</td>
          </tr>
          <tr>
            <td><strong>Probability Range</strong></td>
            <td>[0.35, 0.68]</td>
            <td>Narrow range (conservative predictions)</td>
          </tr>
        </tbody>
      </table>

      <div class="info-box" style="margin-top:16px">
        <strong>üìä Distribution Insight:</strong><br>
        - Mean = 0.573 ‚Üí balanced predictions (slightly more helpful than unhelpful)<br>
        - Narrow range [0.35, 0.68] ‚Üí model conservative (no extreme probabilities)<br>
        - Low std = 0.077 ‚Üí consistent predictions (not bimodal like V2 old project)<br>
        - No probabilities near 0 or 1 ‚Üí calibrated model (no overconfident predictions)
      </div>
    </div>

    <!-- Training Journey -->
    <div class="card card-full">
      <h2>üöÄ Complete Training Journey</h2>
      
      <table>
        <thead>
          <tr><th>Phase</th><th>Model</th><th>Time</th><th>AUC-PR</th><th>Status</th></tr>
        </thead>
        <tbody>
          <tr>
            <td><strong>Phase 1</strong></td>
            <td>V7 Baseline (Manual params)</td>
            <td>2.5 hours</td>
            <td><strong>0.6327</strong></td>
            <td><span class="badge badge-success">‚úì Best</span></td>
          </tr>
          <tr>
            <td><strong>Phase 2</strong></td>
            <td>V7 Auto-tune (Quick preset)</td>
            <td>2.7 hours</td>
            <td>0.6315</td>
            <td><span class="badge badge-info">‚úì Close 2nd</span></td>
          </tr>
          <tr>
            <td><strong>Phase 3</strong></td>
            <td>V7 Prediction (Baseline)</td>
            <td>~10 mins</td>
            <td>‚Äî</td>
            <td><span class="badge badge-success">‚úì Done</span></td>
          </tr>
          <tr>
            <td><strong>Phase 4</strong></td>
            <td>V7_auto Prediction</td>
            <td>~10 mins</td>
            <td>‚Äî</td>
            <td><span class="badge badge-success">‚úì Done</span></td>
          </tr>
        </tbody>
      </table>

      <h3>Timeline Breakdown</h3>
      <ul>
        <li><strong>14:00-16:30:</strong> V7 Baseline training (numLeaves=120, lr=0.03)</li>
        <li><strong>16:30-16:40:</strong> V7 Baseline prediction ‚Üí submission_v7.csv</li>
        <li><strong>16:04-18:50:</strong> V7 Auto-tune training (9 combos √ó 3-fold CV)</li>
        <li><strong>19:12-19:22:</strong> V7_auto prediction ‚Üí submission_v7_auto.csv</li>
      </ul>
    </div>

    <!-- Auto-tuning Results -->
    <div class="card card-full">
      <h2>üîß Auto-tuning Detailed Results</h2>
      
      <h3>Grid Search Configuration</h3>
      <div class="code-block">
        <pre># Quick preset - 9 combinations
numLeaves: [50, 100, 150]
learningRate: [0.05, 0.10, 0.15]
minDataInLeaf: [50]  # fixed

Total runs: 9 combos √ó 3 folds = 27 training runs
Total time: 2.7 hours (6 mins/run average)</pre>
      </div>

      <h3>Top 5 Configurations (by mean AUC-PR)</h3>
      <table>
        <thead>
          <tr><th>Rank</th><th>numLeaves</th><th>learningRate</th><th>Mean AUC-PR</th><th>Std</th></tr>
        </thead>
        <tbody>
          <tr>
            <td><strong>ü•á 1st</strong></td>
            <td>100</td>
            <td>0.15</td>
            <td><strong>0.6315</strong></td>
            <td>0.0012</td>
          </tr>
          <tr>
            <td>ü•à 2nd</td>
            <td>150</td>
            <td>0.15</td>
            <td>0.6312</td>
            <td>0.0011</td>
          </tr>
          <tr>
            <td>ü•â 3rd</td>
            <td>100</td>
            <td>0.10</td>
            <td>0.6309</td>
            <td>0.0013</td>
          </tr>
          <tr>
            <td>4th</td>
            <td>50</td>
            <td>0.15</td>
            <td>0.6305</td>
            <td>0.0014</td>
          </tr>
          <tr>
            <td>5th</td>
            <td>150</td>
            <td>0.10</td>
            <td>0.6301</td>
            <td>0.0012</td>
          </tr>
        </tbody>
      </table>

      <div class="info-box" style="margin-top:16px">
        <strong>üéØ Key Finding:</strong><br>
        - <strong>learningRate=0.15</strong> dominates top positions (1st, 2nd, 4th)<br>
        - <strong>numLeaves=100-150</strong> optimal range (not too simple, not too complex)<br>
        - Low std (0.0011-0.0014) ‚Üí stable across folds ‚Üí generalizes well<br>
        - BUT manual params (numLeaves=120, lr=0.03) STILL better by 0.19%!
      </div>
    </div>

    <!-- Prediction Command Log -->
    <div class="card card-full">
      <h2>üíª Prediction Commands</h2>
      
      <h3>V7 Auto-tune Prediction</h3>
      <div class="code-block">
        <pre>$env:PYSPARK_PYTHON = "C:\Users\LeDangHoangTuan\AppData\Local\Programs\Python\Python311\python.exe"
$env:PYSPARK_DRIVER_PYTHON = "C:\Users\LeDangHoangTuan\AppData\Local\Programs\Python\Python311\python.exe"

& "$env:SPARK_HOME\bin\spark-submit.cmd" `
  --master local[*] `
  --deploy-mode client `
  --packages com.microsoft.azure:synapseml-lightgbm_2.12:1.0.7 `
  --driver-memory 11g `
  --executor-memory 11g `
  --conf spark.driver.maxResultSize=4g `
  --conf spark.sql.shuffle.partitions=64 `
  --conf spark.sql.adaptive.enabled=true `
  "D:\HK7\AmazonReviewInsight\code_v2\models\predict_pipeline_v2.py" `
  --model_path "hdfs://localhost:9000/output_v2/models/lightgbm_v7_auto" `
  --test "hdfs://localhost:9000/output_v2/features_test_v4" `
  --out "hdfs://localhost:9000/output_v2/predictions_v7_auto" `
  --debug_samples 100</pre>
      </div>

      <h3>Parameters Explanation</h3>
      <table>
        <thead>
          <tr><th>Parameter</th><th>Value</th><th>Purpose</th></tr>
        </thead>
        <tbody>
          <tr>
            <td><strong>model_path</strong></td>
            <td>lightgbm_v7_auto</td>
            <td>Best auto-tuned model (numLeaves=100, lr=0.15)</td>
          </tr>
          <tr>
            <td><strong>test</strong></td>
            <td>features_test_v4</td>
            <td>Test features (1.73M √ó 10,017 dims)</td>
          </tr>
          <tr>
            <td><strong>out</strong></td>
            <td>predictions_v7_auto</td>
            <td>Output directory for submission CSV</td>
          </tr>
          <tr>
            <td><strong>debug_samples</strong></td>
            <td>100</td>
            <td>Save first 100 predictions for inspection</td>
          </tr>
          <tr>
            <td><strong>driver-memory</strong></td>
            <td>11g</td>
            <td>Driver memory for large dataset handling</td>
          </tr>
          <tr>
            <td><strong>shuffle.partitions</strong></td>
            <td>64</td>
            <td>Parallelism for join/shuffle operations</td>
          </tr>
        </tbody>
      </table>
    </div>

    <!-- Output Files -->
    <div class="card card-full">
      <h2>üìÅ Generated Output Files</h2>
      
      <table>
        <thead>
          <tr><th>File</th><th>Location</th><th>Size</th><th>Description</th></tr>
        </thead>
        <tbody>
          <tr>
            <td><strong>submission_v7.csv</strong></td>
            <td>output_final/</td>
            <td>53.77 MB</td>
            <td>V7 Baseline predictions (AUC-PR 0.6327) ‚úÖ</td>
          </tr>
          <tr>
            <td><strong>submission_v7_auto.csv</strong></td>
            <td>output_final/</td>
            <td>53.74 MB</td>
            <td>V7 Auto-tune predictions (AUC-PR 0.6315)</td>
          </tr>
          <tr>
            <td><strong>debug_v7_auto.csv</strong></td>
            <td>output_final/</td>
            <td>3.1 KB</td>
            <td>First 100 predictions for debugging</td>
          </tr>
          <tr>
            <td><strong>stats.json</strong></td>
            <td>tmp/predict_logs/</td>
            <td>~1 KB</td>
            <td>Prediction statistics (min, max, mean, std)</td>
          </tr>
          <tr>
            <td><strong>params.txt</strong></td>
            <td>tmp/predict_logs/</td>
            <td>~1 KB</td>
            <td>Prediction parameters log</td>
          </tr>
          <tr>
            <td><strong>day3_v2_training_report.html</strong></td>
            <td>docs_v2/</td>
            <td>~180 KB</td>
            <td>Training report (algorithms + hyperparameters)</td>
          </tr>
          <tr>
            <td><strong>day3_v2_final_report.html</strong></td>
            <td>docs_v2/</td>
            <td>~45 KB</td>
            <td>This final summary report</td>
          </tr>
        </tbody>
      </table>
    </div>

    <!-- Recommendations -->
    <div class="card card-full">
      <h2>üéØ Recommendations & Next Steps</h2>
      
      <div class="success-box">
        <strong>‚úÖ Recommendation: Submit V7 Baseline FIRST</strong><br><br>
        
        <strong>Reasons:</strong><br>
        1. <strong>Higher validation AUC-PR:</strong> 0.6327 vs 0.6315 (+0.19%)<br>
        2. <strong>Better all-around metrics:</strong> Precision 81.59%, Recall 57.67%, F1 67.55%<br>
        3. <strong>Conservative but effective:</strong> Manual hyperparameters well-tuned<br>
        4. <strong>Proven stable:</strong> Single training run, no overfitting signs<br><br>

        <strong>Backup Plan:</strong><br>
        - If V7 Baseline doesn't perform well on leaderboard ‚Üí submit V7 Auto-tune<br>
        - Auto-tune model only 0.19% worse ‚Üí very close alternative<br>
        - Both models have similar prediction distributions ‚Üí minimal risk
      </div>

      <h3>üìä Decision Matrix</h3>
      <table>
        <thead>
          <tr><th>Criterion</th><th>V7 Baseline</th><th>V7 Auto-tune</th><th>Winner</th></tr>
        </thead>
        <tbody>
          <tr>
            <td><strong>Validation AUC-PR</strong></td>
            <td>0.6327</td>
            <td>0.6315</td>
            <td><span class="badge badge-success">Baseline</span></td>
          </tr>
          <tr>
            <td><strong>Training Time</strong></td>
            <td>2.5 hours</td>
            <td>2.7 hours</td>
            <td><span class="badge badge-success">Baseline</span></td>
          </tr>
          <tr>
            <td><strong>Robustness (CV)</strong></td>
            <td>Single run</td>
            <td>3-fold CV</td>
            <td><span class="badge badge-warning">Auto-tune</span></td>
          </tr>
          <tr>
            <td><strong>Hyperparameters</strong></td>
            <td>Manual tuned</td>
            <td>Grid searched</td>
            <td><span class="badge badge-info">Tie</span></td>
          </tr>
          <tr>
            <td><strong>Simplicity</strong></td>
            <td>Simple</td>
            <td>Complex</td>
            <td><span class="badge badge-success">Baseline</span></td>
          </tr>
        </tbody>
      </table>

      <div class="info-box" style="margin-top:20px">
        <strong>üí° Next Actions:</strong><br>
        1. ‚úÖ Copy <code>submission_v7.csv</code> to submission folder<br>
        2. ‚úÖ Upload to competition platform<br>
        3. ‚è≥ Wait for leaderboard score<br>
        4. üìä If score < expected ‚Üí try <code>submission_v7_auto.csv</code><br>
        5. üìù Document final leaderboard results
      </div>
    </div>

    <!-- Lessons Learned -->
    <div class="card card-full">
      <h2>üí° Lessons Learned</h2>
      
      <h3>‚úÖ What Went Well</h3>
      <ul>
        <li><strong>Hyperparameter Tuning:</strong> Auto-tune workflow worked perfectly (9 combos √ó 3-fold CV in 2.7 hrs)</li>
        <li><strong>Prediction Pipeline:</strong> Clean, robust predict_pipeline_v2.py with comprehensive validation</li>
        <li><strong>Feature Engineering:</strong> 10,017 features (10K TF-IDF + 17 numeric) working well</li>
        <li><strong>Memory Management:</strong> 11GB driver memory sufficient for 1.73M predictions</li>
        <li><strong>Documentation:</strong> Comprehensive HTML reports with all details</li>
      </ul>

      <h3>‚ö†Ô∏è Surprises & Insights</h3>
      <ul>
        <li><strong>Manual > Auto:</strong> Manual hyperparameters outperformed auto-tuned by 0.19% (unexpected!)</li>
        <li><strong>Learning Rate:</strong> Higher lr=0.15 dominated auto-tune, but manual lr=0.03 still best</li>
        <li><strong>numLeaves:</strong> Sweet spot 100-120 (not too complex, not too simple)</li>
        <li><strong>Narrow Probability Range:</strong> [0.35, 0.68] ‚Üí model conservative (good calibration)</li>
        <li><strong>Low Variance:</strong> std=0.077 ‚Üí consistent predictions across test set</li>
      </ul>

      <h3>üîß What Could Be Improved</h3>
      <ul>
        <li><strong>Thorough Auto-tune:</strong> Try "thorough" preset (27 combos) instead of "quick" (9 combos)</li>
        <li><strong>Learning Rate Range:</strong> Expand grid to include 0.01-0.05 (current best=0.03)</li>
        <li><strong>Ensemble:</strong> Combine V7 + V7_auto predictions (weighted average)</li>
        <li><strong>Post-processing:</strong> Calibration (Platt scaling) to improve probability estimates</li>
        <li><strong>Feature Selection:</strong> Investigate which features contribute most (SHAP values)</li>
      </ul>
    </div>

    <!-- Technical Summary -->
    <div class="card card-full">
      <h2>üî¨ Technical Summary</h2>
      
      <div style="display:grid;grid-template-columns:1fr 1fr;gap:20px">
        <div>
          <h3>Training Configuration</h3>
          <ul>
            <li><strong>Dataset:</strong> 5M samples (32% of 15.6M)</li>
            <li><strong>Features:</strong> 10,017 dims (10K TF-IDF + 17 numeric)</li>
            <li><strong>Class Ratio:</strong> 1:3 (1.1M helpful vs 3.4M unhelpful)</li>
            <li><strong>Class Weight:</strong> 3.054 for positive class</li>
            <li><strong>Max Depth:</strong> -1 (unlimited, leaf-wise growth)</li>
            <li><strong>Early Stopping:</strong> 200 rounds</li>
            <li><strong>Max Iterations:</strong> 1500 trees</li>
          </ul>
        </div>

        <div>
          <h3>Prediction Configuration</h3>
          <ul>
            <li><strong>Test Samples:</strong> 1,735,280 rows</li>
            <li><strong>Model Type:</strong> LightGBMClassificationModel</li>
            <li><strong>Probability Extraction:</strong> vector_to_array + getItem(1)</li>
            <li><strong>Validation:</strong> Range check [0, 1], no NULLs</li>
            <li><strong>Output Format:</strong> CSV (review_id, probability_helpful)</li>
            <li><strong>File Size:</strong> ~54 MB (1.73M rows)</li>
          </ul>
        </div>
      </div>

      <h3>Infrastructure</h3>
      <ul>
        <li><strong>Spark Version:</strong> 3.4.1 with SynapseML 1.0.7</li>
        <li><strong>Python:</strong> 3.11</li>
        <li><strong>Memory:</strong> 11GB driver + 11GB executor</li>
        <li><strong>Parallelism:</strong> local[*] (all CPU cores)</li>
        <li><strong>Storage:</strong> HDFS (localhost:9000) + local output_final/</li>
        <li><strong>Shuffle Partitions:</strong> 64 (optimized for dataset size)</li>
      </ul>
    </div>

    <!-- Footer -->
    <div style="text-align:center;padding:24px;color:#fff;font-size:0.9em">
      <p><strong>Day 3 V2 Final Report</strong> ‚Äî Generated on November 1, 2025 at 19:30</p>
      <p>Complete journey: Training ‚Üí Auto-tuning ‚Üí Prediction ‚Üí Submission Ready!</p>
      <p style="margin-top:8px">
        <span class="badge badge-success">V7 Baseline: AUC-PR 0.6327 ‚úÖ</span>
        <span class="badge badge-info">V7 Auto-tune: AUC-PR 0.6315</span>
        <span class="badge badge-success">Both submissions ready!</span>
      </p>
      <div style="margin-top:16px;padding:16px;background:rgba(255,255,255,0.1);border-radius:8px">
        <strong>üéâ READY FOR SUBMISSION!</strong><br>
        Recommend: <code>submission_v7.csv</code> (V7 Baseline) first<br>
        Backup: <code>submission_v7_auto.csv</code> (V7 Auto-tune) if needed
      </div>
    </div>
  </div>
</body>
</html>
