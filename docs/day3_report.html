<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>B√°o C√°o Ng√†y 3 - Train Baseline Logistic Regression</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            padding: 40px;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
        }
        
        h1 {
            color: #667eea;
            text-align: center;
            margin-bottom: 10px;
            font-size: 2.5em;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
        }
        
        .subtitle {
            text-align: center;
            color: #666;
            margin-bottom: 30px;
            font-size: 1.1em;
        }
        
        h2 {
            color: #764ba2;
            margin-top: 30px;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 3px solid #667eea;
        }
        
        h3 {
            color: #667eea;
            margin-top: 20px;
            margin-bottom: 10px;
        }
        
        .highlight-box {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 25px;
            border-radius: 15px;
            margin: 20px 0;
            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.3);
        }
        
        .success-box {
            background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
            color: white;
            padding: 20px;
            border-radius: 10px;
            margin: 15px 0;
        }
        
        .warning-box {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
            padding: 20px;
            border-radius: 10px;
            margin: 15px 0;
        }
        
        .metric-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        
        .metric-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
            border-radius: 15px;
            color: white;
            text-align: center;
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.3);
            transition: transform 0.3s ease;
        }
        
        .metric-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 25px rgba(102, 126, 234, 0.4);
        }
        
        .metric-card h3 {
            color: white;
            margin-bottom: 10px;
            font-size: 0.9em;
            text-transform: uppercase;
            letter-spacing: 1px;
        }
        
        .metric-card .value {
            font-size: 2.5em;
            font-weight: bold;
            margin: 10px 0;
        }
        
        .metric-card .change {
            font-size: 1.1em;
            opacity: 0.9;
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
            border-radius: 10px;
            overflow: hidden;
        }
        
        th {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 15px;
            text-align: left;
            font-weight: 600;
        }
        
        td {
            padding: 12px 15px;
            border-bottom: 1px solid #ddd;
        }
        
        tr:hover {
            background-color: #f5f5f5;
        }
        
        .checkmark {
            color: #38ef7d;
            font-weight: bold;
            font-size: 1.2em;
        }
        
        .warning {
            color: #f5576c;
            font-weight: bold;
        }
        
        code {
            background-color: #f4f4f4;
            padding: 2px 8px;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
            color: #764ba2;
        }
        
        .code-block {
            background-color: #282c34;
            color: #abb2bf;
            padding: 20px;
            border-radius: 10px;
            overflow-x: auto;
            margin: 15px 0;
            font-family: 'Courier New', monospace;
        }
        
        .improvement {
            color: #38ef7d;
            font-weight: bold;
        }
        
        .degradation {
            color: #f5576c;
            font-weight: bold;
        }
        
        ul, ol {
            margin-left: 20px;
            margin-top: 10px;
        }
        
        li {
            margin-bottom: 8px;
        }
        
        .footer {
            text-align: center;
            margin-top: 40px;
            padding-top: 20px;
            border-top: 2px solid #ddd;
            color: #666;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üìä B√ÅO C√ÅO NG√ÄY 3</h1>
        <div class="subtitle">
            <strong>Train Baseline Logistic Regression Model</strong><br>
            D·ª± √°n: Amazon Review Helpfulness Prediction | Nh√≥m HK7<br>
            Ng√†y: 26/10/2025 | Th√†nh vi√™n: Tu·∫•n (Infrastructure) & Thanh (Data Science)
        </div>

        <div class="highlight-box">
            <h2 style="color: white; border: none; margin-top: 0;">üéØ M·ª§C TI√äU NG√ÄY 3</h2>
            <ul style="font-size: 1.1em;">
                <li><strong>Thi·∫øt l·∫≠p baseline benchmark:</strong> Train dummy classifiers ƒë·ªÉ x√°c ƒë·ªãnh ng∆∞·ª°ng t·ªëi thi·ªÉu</li>
                <li><strong>Train Logistic Regression baseline:</strong> Model ƒë∆°n gi·∫£n v·ªõi TF-IDF + metadata</li>
                <li><strong>ƒê√°nh gi√° hi·ªáu su·∫•t:</strong> So s√°nh v·ªõi baseline, x√°c ƒë·ªãnh c·∫£i ti·∫øn c·∫ßn thi·∫øt</li>
                <li><strong>Target: AUC-PR > 0.25</strong> (cao h∆°n baseline dummy)</li>
            </ul>
        </div>

        <h2>üìà K·∫æT QU·∫¢ CH√çNH</h2>
        
        <div class="metric-grid">
            <div class="metric-card">
                <h3>AUC-PR Score</h3>
                <div class="value">0.4353</div>
                <div class="change"><span class="checkmark">‚úì</span> +73.3% vs baseline</div>
            </div>
            
            <div class="metric-card">
                <h3>AUC-ROC Score</h3>
                <div class="value">0.5967</div>
                <div class="change">T·ªët h∆°n random (0.5)</div>
            </div>
            
            <div class="metric-card">
                <h3>Accuracy</h3>
                <div class="value">70.12%</div>
                <div class="change">Trade-off cho class balance</div>
            </div>
            
            <div class="metric-card">
                <h3>Training Samples</h3>
                <div class="value">80,500</div>
                <div class="change">24.80% positive class</div>
            </div>
        </div>

        <div class="success-box">
            <h3 style="color: white; margin-top: 0;">üéâ TH√ÄNH C√îNG: V∆∞·ª£t M·ª•c Ti√™u Ng√†y 3</h3>
            <p style="font-size: 1.1em; margin-top: 10px;">
                <strong>AUC-PR = 0.4353 >> 0.2511 (baseline dummy)</strong><br>
                Model ƒë√£ h·ªçc ƒë∆∞·ª£c pattern t·ª´ text v√† features, kh√¥ng c√≤n predict random!
            </p>
        </div>

        <h2>üîç SO S√ÅNH V·ªöI BASELINE</h2>
        
        <table>
            <thead>
                <tr>
                    <th>Model</th>
                    <th>Strategy</th>
                    <th>AUC-PR</th>
                    <th>AUC-ROC</th>
                    <th>Accuracy</th>
                    <th>C·∫£i thi·ªán</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><strong>Baseline Dummy</strong></td>
                    <td>Most Frequent (predict all negative)</td>
                    <td>0.2511</td>
                    <td>-</td>
                    <td>74.89%</td>
                    <td>-</td>
                </tr>
                <tr>
                    <td><strong>Baseline Dummy</strong></td>
                    <td>Random Stratified (prob = 0.248)</td>
                    <td>0.2511</td>
                    <td>-</td>
                    <td>-</td>
                    <td>-</td>
                </tr>
                <tr>
                    <td><strong>Baseline Dummy</strong></td>
                    <td>Uniform Random (prob = 0.5)</td>
                    <td>0.2511</td>
                    <td>-</td>
                    <td>-</td>
                    <td>-</td>
                </tr>
                <tr style="background-color: #e8f5e9;">
                    <td><strong>Logistic Regression</strong></td>
                    <td>TF-IDF + metadata features</td>
                    <td><strong>0.4353</strong></td>
                    <td><strong>0.5967</strong></td>
                    <td>70.12%</td>
                    <td><span class="improvement">+73.3%</span></td>
                </tr>
            </tbody>
        </table>

        <h2>‚öôÔ∏è PIPELINE & FEATURES</h2>
        
        <h3>1. D·ªØ Li·ªáu Training</h3>
        <ul>
            <li><strong>Train set:</strong> 80,500 records (80.2%)</li>
            <li><strong>Test set:</strong> 19,863 records (19.8%)</li>
            <li><strong>Class distribution:</strong>
                <ul>
                    <li>Positive (helpful=1): 19,963 samples (24.80%)</li>
                    <li>Negative (helpful=0): 60,537 samples (75.20%)</li>
                    <li>Imbalance ratio: 3.03:1</li>
                </ul>
            </li>
            <li><strong>Class weighting:</strong> pos_weight = 3.032 (ƒë·ªÉ balance loss)</li>
        </ul>

        <h3>2. Feature Engineering</h3>
        <table>
            <thead>
                <tr>
                    <th>Feature Type</th>
                    <th>Features</th>
                    <th>Details</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><strong>Text Features</strong></td>
                    <td>TF-IDF</td>
                    <td>
                        ‚Ä¢ numFeatures: 20,000<br>
                        ‚Ä¢ minDocFreq: 5<br>
                        ‚Ä¢ Source: clean_text (preprocessed)
                    </td>
                </tr>
                <tr>
                    <td><strong>Metadata Features</strong></td>
                    <td>star_rating</td>
                    <td>
                        ‚Ä¢ Range: 1-5 stars<br>
                        ‚Ä¢ Important signal for helpfulness
                    </td>
                </tr>
                <tr>
                    <td><strong>Engineered Features</strong></td>
                    <td>review_length</td>
                    <td>
                        ‚Ä¢ Log-transformed token count<br>
                        ‚Ä¢ Helpful reviews 4.1x longer
                    </td>
                </tr>
            </tbody>
        </table>

        <h3>3. Model Configuration</h3>
        <div class="code-block">
LogisticRegression(
    maxIter=80,
    regParam=0.0,           # No regularization
    elasticNetParam=0.0,    # Pure L2 if regularized
    weightCol='weight',     # Class balancing
    family='binomial'
)

Pipeline:
  1. HashingTF (20K features, minDocFreq=5)
  2. IDF (inverse document frequency)
  3. VectorAssembler (tfidf + star_rating + review_length)
  4. LogisticRegression (with class weights)
        </div>

        <h2>üìä PH√ÇN T√çCH K·∫æT QU·∫¢</h2>
        
        <h3>‚úÖ ƒêi·ªÉm M·∫°nh</h3>
        <div class="success-box">
            <ol>
                <li><strong>AUC-PR tƒÉng 73.3%:</strong> T·ª´ 0.2511 ‚Üí 0.4353
                    <ul>
                        <li>Ch·ª©ng t·ªè model th·∫≠t s·ª± h·ªçc ƒë∆∞·ª£c pattern, kh√¥ng random</li>
                        <li>TF-IDF ƒë√£ capture ƒë∆∞·ª£c t·ª´ v·ª±ng quan tr·ªçng</li>
                        <li>Metadata features (star_rating, review_length) c√≥ t√°c ƒë·ªông</li>
                    </ul>
                </li>
                <li><strong>AUC-ROC = 0.5967:</strong> T·ªët h∆°n random guess (0.5)
                    <ul>
                        <li>Model c√≥ kh·∫£ nƒÉng ph√¢n bi·ªát positive/negative</li>
                        <li>Trade-off precision/recall ƒë∆∞·ª£c c·∫£i thi·ªán</li>
                    </ul>
                </li>
                <li><strong>Class balancing hi·ªáu qu·∫£:</strong>
                    <ul>
                        <li>Pos_weight = 3.032 gi√∫p model kh√¥ng ignore minority class</li>
                        <li>Kh√¥ng c√≤n predict to√†n negative nh∆∞ dummy baseline</li>
                    </ul>
                </li>
            </ol>
        </div>

        <h3>‚ö†Ô∏è H·∫°n Ch·∫ø & C∆° H·ªôi C·∫£i Ti·∫øn</h3>
        <div class="warning-box">
            <ol>
                <li><strong>Accuracy gi·∫£m 6.4%:</strong> T·ª´ 74.89% ‚Üí 70.12%
                    <ul>
                        <li><strong>ƒê√¢y l√† ƒëi·ªÅu T·ªêT:</strong> Trade-off cho class balance</li>
                        <li>Dummy baseline ƒë·∫°t 74.89% v√¨ predict all negative (cheat!)</li>
                        <li>LogReg ƒë·∫°t 70.12% v√¨ c·ªë g·∫Øng predict c·∫£ 2 classes</li>
                    </ul>
                </li>
                <li><strong>AUC-PR c√≤n th·∫•p (0.4353):</strong>
                    <ul>
                        <li>Target l√Ω t∆∞·ªüng: AUC-PR > 0.60</li>
                        <li>C·∫ßn th√™m features: sentiment, brand, category</li>
                        <li>C·∫ßn th·ª≠ models ph·ª©c t·∫°p h∆°n: LightGBM, XGBoost</li>
                    </ul>
                </li>
                <li><strong>TF-IDF limitations:</strong>
                    <ul>
                        <li>Kh√¥ng capture context (word order, semantics)</li>
                        <li>99.86% sparsity ‚Üí nhi·ªÅu noise</li>
                        <li>N√™n th·ª≠: embeddings, N-grams</li>
                    </ul>
                </li>
            </ol>
        </div>

        <h2>üî¨ TECHNICAL INSIGHTS</h2>
        
        <h3>1. T·∫°i Sao Accuracy Gi·∫£m L·∫°i T·ªët?</h3>
        <p>
            Trong <strong>imbalanced dataset</strong> (75% negative, 25% positive), accuracy l√† metric <strong>misleading</strong>:
        </p>
        <ul>
            <li><strong>Dummy baseline:</strong> Predict all negative ‚Üí 74.89% accuracy (nh∆∞ng AUC-PR = 0.2511)</li>
            <li><strong>Logistic Regression:</strong> Predict c·∫£ 2 classes ‚Üí 70.12% accuracy (nh∆∞ng AUC-PR = 0.4353)</li>
            <li><strong>K·∫øt lu·∫≠n:</strong> AUC-PR l√† metric ch√≠nh x√°c h∆°n cho imbalanced data!</li>
        </ul>

        <h3>2. Class Weighting Strategy</h3>
        <p>
            Pos_weight = 3.032 nghƒ©a l√† m·ªói positive sample ƒë∆∞·ª£c nh√¢n weight 3.032 trong loss function:
        </p>
        <div class="code-block">
Loss = -[w_1 * y * log(p) + w_0 * (1-y) * log(1-p)]

Where:
  w_1 = 3.032 (positive class weight)
  w_0 = 1.0 (negative class weight)
  
Effect:
  - Model penalized 3x more for misclassifying positive samples
  - Encourages model to learn positive patterns better
        </div>

        <h3>3. Sample Size Effect</h3>
        <table>
            <thead>
                <tr>
                    <th>Train Size</th>
                    <th>Positive %</th>
                    <th>AUC-PR</th>
                    <th>Note</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>10,000</td>
                    <td>12.54%</td>
                    <td>0.2019</td>
                    <td><span class="warning">Sample bias - th·∫•p h∆°n baseline!</span></td>
                </tr>
                <tr style="background-color: #e8f5e9;">
                    <td><strong>80,500</strong></td>
                    <td><strong>24.80%</strong></td>
                    <td><strong>0.4353</strong></td>
                    <td><span class="checkmark">‚úì</span> <strong>Full data - k·∫øt qu·∫£ t·ªët</strong></td>
                </tr>
            </tbody>
        </table>
        <p>
            <strong>Lesson learned:</strong> Sample nh·ªè (10K) kh√¥ng ƒë·∫°i di·ªán cho distribution c·ªßa full dataset ‚Üí k·∫øt qu·∫£ kh√¥ng ƒë√°ng tin c·∫≠y!
        </p>

        <h2>üìã C√îNG VI·ªÜC ƒê√É HO√ÄN TH√ÄNH</h2>
        
        <h3>1. Infrastructure (Tu·∫•n)</h3>
        <ul>
            <li><span class="checkmark">‚úì</span> Refactor <code>train_spark_logreg.py</code> ƒë·ªÉ s·ª≠ d·ª•ng pre-split data</li>
            <li><span class="checkmark">‚úì</span> Implement baseline dummy classifiers (3 strategies)</li>
            <li><span class="checkmark">‚úì</span> Setup train/test split v·ªõi stratification (80/20)</li>
            <li><span class="checkmark">‚úì</span> Configure Spark v·ªõi 6GB driver, 4GB executor memory</li>
        </ul>

        <h3>2. Data Science (Thanh)</h3>
        <ul>
            <li><span class="checkmark">‚úì</span> Thi·∫øt k·∫ø TF-IDF pipeline (20K features, minDF=5)</li>
            <li><span class="checkmark">‚úì</span> Implement class balancing v·ªõi pos_weight</li>
            <li><span class="checkmark">‚úì</span> Feature engineering: TF-IDF + star_rating + review_length</li>
            <li><span class="checkmark">‚úì</span> Evaluation metrics: AUC-PR, AUC-ROC, Accuracy</li>
        </ul>

        <h3>3. Documentation</h3>
        <ul>
            <li><span class="checkmark">‚úì</span> File inventory audit (12 files, no redundancy)</li>
            <li><span class="checkmark">‚úì</span> <code>file_inventory.md</code>: Complete project documentation</li>
            <li><span class="checkmark">‚úì</span> Baseline benchmark results: <code>baseline_dummy.json</code></li>
            <li><span class="checkmark">‚úì</span> Model artifacts saved: <code>logreg_baseline_full/</code></li>
        </ul>

        <h2>üöÄ K·∫æ HO·∫†CH NG√ÄY 4</h2>
        
        <div class="highlight-box">
            <h3 style="color: white; margin-top: 0;">M·ª•c Ti√™u: Features V2 + Model Improvements</h3>
            <ol style="font-size: 1.05em;">
                <li><strong>Feature Engineering V2:</strong>
                    <ul>
                        <li>Th√™m sentiment features: compound, positive, negative, neutral scores</li>
                        <li>Th√™m metadata: brand, category, product_avg_rating, product_total_ratings</li>
                        <li>Th√™m interaction features: rating_deviation, is_long_review</li>
                        <li>Target: 25+ features (hi·ªán t·∫°i: TF-IDF + 2 metadata)</li>
                    </ul>
                </li>
                <li><strong>Model Experimentation:</strong>
                    <ul>
                        <li>Hyperparameter tuning: regParam, elasticNetParam, maxIter</li>
                        <li>Try different numFeatures: 10K, 20K, 50K</li>
                        <li>Experiment with N-grams (unigram + bigram)</li>
                        <li>Target: AUC-PR > 0.50</li>
                    </ul>
                </li>
                <li><strong>Evaluation Framework:</strong>
                    <ul>
                        <li>Implement PR curve visualization</li>
                        <li>Feature importance analysis</li>
                        <li>Confusion matrix & classification report</li>
                    </ul>
                </li>
            </ol>
        </div>

        <h3>Expected Metrics (Day 4 Target)</h3>
        <table>
            <thead>
                <tr>
                    <th>Model</th>
                    <th>Features</th>
                    <th>AUC-PR Target</th>
                    <th>AUC-ROC Target</th>
                </tr>
            </thead>
            <tbody>
                <tr style="opacity: 0.5;">
                    <td>Day 3 Baseline</td>
                    <td>TF-IDF + 2 metadata</td>
                    <td>0.4353</td>
                    <td>0.5967</td>
                </tr>
                <tr style="background-color: #fff3e0;">
                    <td><strong>Day 4 Target</strong></td>
                    <td>TF-IDF + sentiment + 6 metadata + interactions</td>
                    <td><strong>> 0.50</strong></td>
                    <td><strong>> 0.65</strong></td>
                </tr>
                <tr style="background-color: #e3f2fd;">
                    <td>Day 5 Target (LightGBM)</td>
                    <td>All features + tuning</td>
                    <td>> 0.60</td>
                    <td>> 0.75</td>
                </tr>
            </tbody>
        </table>

        <h2>üìÅ OUTPUT FILES</h2>
        
        <ul>
            <li><strong>Model artifacts:</strong> <code>output/logreg_baseline_full/</code>
                <ul>
                    <li><code>metadata/</code> - Pipeline metadata</li>
                    <li><code>stages/</code> - HashingTF, IDF, VectorAssembler, LogReg stages</li>
                    <li><code>metrics.json/</code> - Model evaluation results</li>
                </ul>
            </li>
            <li><strong>Baseline benchmark:</strong> <code>output/baseline_dummy.json</code></li>
            <li><strong>Train/test data:</strong>
                <ul>
                    <li><code>hdfs://localhost:9000/datasets/amazon/movies/parquet/train/</code></li>
                    <li><code>hdfs://localhost:9000/datasets/amazon/movies/parquet/test/</code></li>
                </ul>
            </li>
            <li><strong>Documentation:</strong> <code>file_inventory.md</code></li>
        </ul>

        <h2>üí° KEY TAKEAWAYS</h2>
        
        <div class="success-box">
            <ol style="font-size: 1.05em;">
                <li><strong>Baseline benchmarking is critical:</strong> Dummy classifiers cho bi·∫øt ng∆∞·ª°ng t·ªëi thi·ªÉu (0.2511)</li>
                <li><strong>AUC-PR > Accuracy:</strong> Trong imbalanced data, AUC-PR l√† metric ƒë√°ng tin c·∫≠y h∆°n</li>
                <li><strong>Class weighting works:</strong> Pos_weight = 3.032 gi√∫p model h·ªçc c·∫£ 2 classes</li>
                <li><strong>Sample size matters:</strong> 10K sample kh√¥ng ƒë·∫°i di·ªán ‚Üí k·∫øt qu·∫£ sai l·ªách</li>
                <li><strong>TF-IDF is a good start:</strong> 20K features ƒë·ªß ƒë·ªÉ beat baseline, nh∆∞ng c·∫ßn th√™m features ƒë·ªÉ improve</li>
            </ol>
        </div>

        <div class="footer">
            <p><strong>Amazon Review Helpfulness Prediction</strong></p>
            <p>Nh√≥m HK7 | Tu·∫•n (Infrastructure) & Thanh (Data Science)</p>
            <p>Day 3 Completed: 26/10/2025 23:05</p>
            <p style="margin-top: 10px;">
                <strong>Next:</strong> Day 4 - Features V2 & Model Improvements<br>
                <strong>Goal:</strong> AUC-PR > 0.50 | AUC-ROC > 0.65
            </p>
        </div>
    </div>
</body>
</html>
